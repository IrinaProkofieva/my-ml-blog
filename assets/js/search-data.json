{
  
    
        "post0": {
            "title": "Что это за цифра?",
            "content": "import torch from torch import exp import matplotlib.pyplot as plt from fastai.data.external import * from fastai.vision.all import * . В этой статье будет показано, как написать простейшую модель для распознавания чисел с нуля. Но для начала разберемся, как вообще происходит обучение модели. . &#1057;&#1093;&#1077;&#1084;&#1072; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; . Представим, как должна выглядеть наша модель. Мы подаем ей на вход изображение размером X на Y пикселей, она выполняет некоторые вычисления и на выходе выдает нам один из следующих результатов: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}. Другими словами, на вход подается X*Y значений - значения, который принимает каждый из пикселей, на выходе получаем 10 значений - вероятность принадлежности к каждому из классов, после этого выбираем класс, вероятность принадлежности к которому наибольшая - это и есть наш ответ. . Каким образом можно определить принадлежность картинки к одному из классов? Так как каждая цифра пишется имеет свою форму, свой силует, то можно понять, что какие-то зоны картинки будут больше задействованы у одной цифры и меньше - у другой. То есть можно сказать, что для каждой цифры какие-то пиксели будут задействованы с большей вероятностью, какие-то - с меньшей. Если мы каждому пикселю для каждой цифры сопоставим определенный вес, то по сумме произведений весов на значения соответсвующих пикселей можно будет сделать предположение, какая цифра перед нами. Однако функция w*x не очень &quot;эластична&quot;, например, если x (значение пикселя) равен 0, то как ни меняй w (вес), произведение останется 0. Со школы мы знаем, что функция прямой имеет вид y = w*x + b, её мы и будем использовать. Переменную b обозначим как сдвиг. Оставим пока такое несколько упрощенное представление о работе модели и пойдем дальше. . Давайте попробуем схематично изобразить такую модель. Сразу это сделать может быть трудновато, поэтому для начала рассмотрим более простой случай: пусть у нас есть только два варианта. Например, будем различать нули и единицы. Соответственно, нам на выходе понадобится только одно значение: условно, можно считать, если оно принимает значение больше нуля, то на изображении ноль, иначе - единица. Тогда схема будет примерно следующей: . . Еще раз посмотрим на схему и попробуем понять. На входе n значений - значения пикселей, где n=X*Y (X, Y - высота и ширина рисунка в пикселях). Далее мы должны с этими параметрами что-то сделать, получить какие-то другие значения, что достигается засчет весов w и сдвига b. Веса и сдвиг вместе называются параметрами. Именно эти параметры мы можем изменять во время обучения, чтобы достигнуть наибольшей точности. Преобразовав входные значения с помощью линейного преобразования (умножаем вход на веса, складываем и добавляем сдвиг), мы получаем первый линейный слой. В нашем простом случае ограничимся одним единственным скрытым слоем. Чтобы получить единственное значение, говорящее нам - ноль это или единица, применим к результату некоторую функцию. Эту функцию называют функцией активации. О ней поговорим позже, но пока можно сказать, что применяем мы ее, поскольку мы же хотим каким-то образом ограничить значения, выдаваемые нашей моделью, чтобы на их основе делать какие-либо выводы. То, что нам выдаст эта функция, и будет нашим выходным значением. . С простым случаем вроде разобрались. Что же происходит в случае, когда нам нужно на выходе не одно, на несколько значений? Если мы хотим определять все цифры, а не только нули и единицы, то нам, как ни крути, понадобится 10 выходных значений. Схема для такого случая будет расширением схемы, которую мы только что разобрали. Давайте посмотрим: . . Все абсолютно аналогично, просто на первом слое у нас не n значений, а n*10. Соответственно, изменяется и размерность массивов параметров: веса становятся двумерным массивом [n,10], а сдвиг задается одномерным массивом длиной 10. После линейного преобразования мы получаем некоторые 10 значений, которые после прохождения через функцию активации дадут нам 10 других значений - вероятности принадлежности к каждой из 10 цифр. После этого можно выбрать один класс - вероятность принадлежности к которому больше всего. Эта последовательность действий будет происходить для всех изображений, которые мы подаем на вход нашей модели. . &#1051;&#1080;&#1085;&#1077;&#1081;&#1085;&#1099;&#1081; &#1089;&#1083;&#1086;&#1081; &#1080; &#1092;&#1091;&#1085;&#1082;&#1094;&#1080;&#1103; &#1072;&#1082;&#1090;&#1080;&#1074;&#1072;&#1094;&#1080;&#1080; . Как это все выглядит в коде? Входные данные - массив [k,X*Y], где k - количество изображений, на которых мы хотим определить цифру; массив весов имеет размерность [X*Y,10]; массив сдвигов - [1,10]. Конечно, вы могли заметить, что умножение входных параметров на вес и последующее суммирование - это матричное умножение, в результате которого получаем массив размером [k,10]. После прибавления к этому массиву массива сдвигов размерность не изменяется. . Давайте посмотрим на код, отвечающий за линейное преобразование: . #задаем линейный слой def linear1(xb): return xb@weights + bias . Символ &quot;@&quot; здесь отвечает за умножение матриц. . Поговорим теперь о функции активации. Значения, которые выдает линейный слой, могут принимать совершенно разные значения от -∞ до ∞ . Хотелось бы ограничить их, скажем, значениями от 0 до 1. Тогда результаты применения функции можно будет трактовать как вероятность принадлежности к классу. Именно это будет делать функция активации: каждому значению на всей числовой прямой будем ставить в соответствие значение от 0 до 1. . Такая функция у нас есть: она называется сигмоида, задается выражением 1/(1+exp(-x)) и выглядит следующим образом: . def sigmoid(x): return 1/(1+exp(-x)) x = torch.arange(-4,4,0.2) plt.plot(x,sigmoid(x)) plt.show() . Она прекрасно работает, в случае одного выходного значения, фактически выдавая вероятность принадлежности к одному из двух классов. Например, в том простом случае, когда мы отличаем изображения нулей от изображений единиц: чем результат сигмоиды ближе к 1, тем вероятнее, что на картинке ноль. . Но когда мы хотим распознать 10 цифр, ситуация немного меняется. Памятуя о том, что результаты функции активации мы хотим трактовать как вероятности принадлежности к каждому из классов, приходится внести некоторые изменения к требованиям к данной функции. В нашем случае функции активации подается 10 значений, поэтому кроме требования принадлежности результатов отрезку [0,1], добавляется требование равенства единице суммы всех этих значений. В самом деле, сумма вероятностей всех исходов событий всегда равняется 1. . Тут нам на помощь приходит функция softmax. Она задается следующим образом: . def softmax(x): return exp(x)/exp(x).sum(dim = 1, keepdim = True) . Softmax принимает на вход массив значений и преобразует его в массив, в котором каждое число лежит в отрезке от 0 до 1 и сумма всех значений равна 1. Это мультикатегориальный аналог сигмоиды. . Посмотрим, как это работает: . #Пусть у нас есть две картинки и три класса. После линейного преобразования мы получили следующие значения: out = torch.tensor([[0.02,-2.49,1.25], [0.01,-3.4,1.1]]) #Применим экспоненциальную функцию exponential = exp(out) #Применим softmax sftmx = softmax(out) print(&#39;Exp(out):&#39;,exponential, &#39;sum:&#39;, exponential.sum(dim=1)) print(&#39;Softmax(out):&#39;, sftmx, &#39;sum:&#39;, sftmx.sum(dim=1)) . Exp(out): tensor([[1.0202, 0.0829, 3.4903], [1.0101, 0.0334, 3.0042]]) sum: tensor([4.5935, 4.0476]) Softmax(out): tensor([[0.2221, 0.0180, 0.7599], [0.2495, 0.0082, 0.7422]]) sum: tensor([1.0000, 1.0000]) . На таком небольшом примере удобно попробовать подсчитать все самому и наглядно увидеть, как работает softmax. . Экспоненциальная функция внутри softmax-а гарантирует, что все значения будут положительны, а деление на сумму гарантирует, что все значения будут суммироваться к 1. Кроме этого, так как экспонента растет быстро, даже небольшое превосходство одного значения над другим будет сильно заметно после применения данной функции активации. . &#1057;&#1090;&#1086;&#1093;&#1072;&#1089;&#1090;&#1080;&#1095;&#1077;&#1089;&#1082;&#1080;&#1081; &#1075;&#1088;&#1072;&#1076;&#1080;&#1077;&#1085;&#1090;&#1085;&#1099;&#1081; &#1089;&#1087;&#1091;&#1089;&#1082; &#1080; &#1092;&#1091;&#1085;&#1082;&#1094;&#1080;&#1103; &#1087;&#1086;&#1090;&#1077;&#1088;&#1100; . Теперь мы имеем представление о том, как будет выглядеть наша модель. Разберемся, как мы будем ее обучать. . Цель обучения модели - подобрать параметры так, чтобы модель делала правильные предсказания на входных данных с удовлетворяющей нас точностью. . Чтобы подобрать параметры таким образом, мы будем скармливать модели картинки с уже известными ответами - помеченный датасет. Ожидается, что модель возьмет картинку, прогонит ее по алгоритму, который мы разобрали выше, сравнит свое предсказание с правильным ответом и откорректирует параметры, если ответ не сойдется. В данной последовательности действий наибольшую сложность предстваляет именно корректировка параметров. Каким образом их изменять, насколько и в какую сторону? Давайте попробуем разобраться. . Очевидно, корректировать параметры надо так, чтобы качество предсказаний улучшалось. Введем некую функцию, которая бы показывала нам, насколько хорошо предсказывает наша модель, в конкретных числовых значениях, а не в абстрактных категориях &quot;хорошо&quot; и &quot;плохо&quot;. Такую функцию будем называть функцией потерь. Условимся, что чем меньшее значение она принимает, тем лучше предсказывает модель. . Тогда целью корректировки параметров становится минимизация функции потерь. Будем решать задачу минимизации с помощью градиентного спуска. Напомню, что градиент n-мерной функции - это вектор, компоненты которого являются частными производными функции по всем ее аргументам. Градиент показывает направление и скорость наискорейшего роста функции (другими словами, помогает найти самый крутой подъем). . Вспомним, как работает градиент на простеньком примере: . #Пусть у нас задана следующая функция, принимающая вектор в качестве параметра: def f(x): return (x**2).sum() #Возьмем в качетсве аргумента вектор (2,-3,7) и с помощью функции requires_grad_() укажем, #что в будущем мы будем брать производную по этому аргументу inp = torch.tensor([2.,-3.,7.]).requires_grad_() #Обратите внимание, что при выводе указывается не только значение функции, но и функция градиента y = f(inp) print(y) . tensor(62., grad_fn=&lt;SumBackward0&gt;) . #Теперь посчитаем само значение градиента для данного аргумента. y.backward() #Чтобы получить это значение, обращаемся к параметру grad аргумента inp print(inp.grad) . tensor([ 4., -6., 14.]) . Если вспомнить старшие классы школы и посчитать частные производные функции, то можно увидеть, что так и получится. . Градиент говорит нам о крутизне функции, поэтому можно предположить, что если абсолютное значение его мало, то мы близки к оптимальному значению (в точках локальных минимумов и максимумов градиент равен 0). Отрицательные значения говорят о том, что идет спуск, положительные - что идет подъем. . Отлично, градиент вспомнили, двигаемся дальше. . Чтобы достичь минимума функции будем изменять наши параметры в зависимости от их градиента: . w -= (w.grad * lr) . Так как градиент показывает направление наикрутейшего подъема, а нам нужен минимум, а не максимум функции, мы будем двигать наши параметры в направлении антиградиента, отсюда в формуле выше и возникает знак минус. . lr в предыдущей формуле - learning rate, темп обучения - параметр, который влияет на величину шага изменения параметров. Обычно темп обучения принимает небольшие значения, от 0.1 до 0.00001, в зависимости от значений конкретной задачи. Если взять этот параметр слишком большим, то есть риск проскочить мимо минимума на каком-то шаге, значения функции потерь начнут увеличиваться или будут сходиться очень-очень долго, практически оставаясь на одном и том же месте, а если взять темп обучения, наоборот, слишком маленьким, то оптимизация параметров, а значит и весь процесс обучения модели, займет очень много времени. . *Изображения взяты из курса fastai 2021* . Теперь должно быть приблизительно понятно, как минимизировать функцию потерь. Но остается вопрос: как выбрать эту самую функцию? Разберемся. . Во-первых, зачем вообще нужна функция потерь? Как я уже говорила, она численно показывает, наколько хороша наша модель при данных параметрах. Почему тогда мы не можем взять в качестве неё отношение правильных ответов к общему числу предсказаний, которое используем, когда хотим другим рассказать, насколько точна наша модель? Представим такую ситуацию: мы хотим узнать по картинке, кто на рисунке - собака или кошка. Мы считаем, что если ответ модели больше 0.5, то это кошка, иначе собака. На какой-то момент наши параметры имеют значения [-3.5, 1.495, 703.04] и модель с такими параметрами дает нам следующие предсказания для четырех входных данных - [0.7, 0.34, 0.2, 0.999], то есть кошка-собака-собака-кошка. А правильные ответы для этих четырех изображений - собака-собака-собака-собака. То есть два правильных предсказания из четырех, точность модели 2/4 = 0.5. Мы хотим ненамного изменить параметры и посмотреть, как изменятся предсказания модели. Меняем параметры на несколько сотых: [-3.55, 1.5, 703.02]. В итоге получаем следующие предсказания для тех же входных данных: [0.51, 0.29, 0.09, 0.63]. Видно, что полученные ответы стали гораздо лучше, уменьшившись в сторону ответа &quot;собака&quot;, а значит мы меняем параметры в верном направлении. Однако конечные ответы модель выдает все те же: кошка-собака-собака-кошка, а значит, точность осталась прежней: 0.5. Поэтому, если в качестве функции потерь мы возьмем данное отношение, то мы просто не заметим улучшение в работе модели и не будем знать, куда двигать параметры. Другими словами, данное значение точности модели меняется только при изменении самых конечных ответов - предсказаний классов, такая функция является ступенчатой функцией и производная по ней практически везде (кроме точек разрыва) равна 0, а значит с ее помощью нельзя изменить параметры. . Поэтому-то нам и нужно брать в качестве функции потерь такие функции, которые будут не столько информативны для человека, сколько удобны для дальнейших вычислений, функции, по которым можно брать производные, чтобы можно было заметить влияние, которое оказывает малейшее изменение параметра. . Функция потерь берет в качестве параметра не сами параметры, а предсказания и сравнивает их с правильными ответами. . Пожалуй, первое, что приходит на ум - посчитать среднюю удаленность предсказаний от правильных ответов. Это было бы удобно, если бы у нас было всего два класса: 0 и 1. Тогда мы могли бы сделать следующее (считаем, что к предсказаниям уже применена функция активации и они имеют значение от 0 до 1): . def loss(preds, targets): ans = [] for t, p in zip(targets, preds): if t == 1: ans.append(1-p) else: ans.append(p) return torch.tensor(ans).mean() #Попробуем на конкретном примере loss(torch.tensor([0.9, 0.4, 0.2]),torch.tensor([1,0,1])) . tensor(0.4333) . или то же самое, но в одну строчку и быстрее: . def loss(preds, targets): return torch.where(targets==1, 1-preds, preds).mean() #Проверим на том же примере на всякий случай loss(torch.tensor([0.9, 0.4, 0.2]),torch.tensor([1,0,1])) . tensor(0.4333) . Как действует данная функция? Рассмотрим на нашем примере с предсказаниями [0.9, 0.4, 0.2] и ответами [1, 0, 1]. Что такое эти предсказания? Если задуматься, то это вероятности принадлежности входных значений к классу 0. Действительно, раз мы считаем, что значения &gt;= 0.5 - это класс 0, а значения &lt; 0.5 - класс 1, то чем больше значение, тем скорее это 0 класс, а чем меньше значение, тем вероятнее, что это 1 и тем менее вероятно это 0. То есть если правильный ответ 0, то мы оставляем такое значение, какое есть, а если 1, то берем значение (1-предсказание), затем берем среднее из этих значений. Получается, мы находим среднее из вероятностей принадлежности каждого входного объекта к истинному классу. . Как бы нам сделать так, чтобы всё считалось по тому же приципу и в случае, когда классов больше, чем два? Если мы возьмем конкретный пример, то сразу станет понятно, что у нас для этого все есть: . # Пусть у нас 6 картинок и 3 класса, модель выдает следующие предсказания preds = torch.randn((6,3))*2 preds . tensor([[ 1.8121, -1.3010, 4.1523], [-1.9579, -0.1233, -1.5999], [ 4.0000, -1.6705, 1.9482], [ 0.5459, 1.9679, 5.7474], [ 0.3846, -1.4243, -1.0640], [ 0.8246, 2.4619, -4.3599]]) . # Применим функцию активации softmax smx_preds = softmax(preds) smx_preds . tensor([[8.7503e-02, 3.8907e-03, 9.0861e-01], [1.1503e-01, 7.2042e-01, 1.6455e-01], [8.8343e-01, 3.0445e-03, 1.1353e-01], [5.3569e-03, 2.2205e-02, 9.7244e-01], [7.1493e-01, 1.1713e-01, 1.6794e-01], [1.6269e-01, 8.3640e-01, 9.1145e-04]]) . #Пусть правильные ответы задаются следующим образом targ = torch.tensor([0,1,0,2,2,0]) . Теперь у нас есть вероятности, с которыми каждая картинка принадлежит к каждому из классов по мнению модели. Но ведь это то, что мы считали в бинарном случае! Значит, нам остается только взять среднее из вероятностей, с которыми объекты принадлежат к верным классам. Это легко сделать, достаточно взять для каждого обхекта предсказание с индексом - верным ответом: . ndxs = range(6) nll_loss = smx_preds[ndxs,targ].mean() nll_loss . tensor(0.4991) . Такая функция потерь называется NLL - Negative Log Likelihood. Но несмотря на название, как вы заметили, логарифмы в ней не используются. Дело в том, что логарифм обычно используют перед тем, как применить эту функцию. Зачем - рассказываю ниже. . Недостаток функции потерь NLL в том, что она получает и выдает значения от 0 до 1, так как работает с вероятностями. И получается, например, что разница между значениями 0.99 и 0.999 не так заметна, хотя выходит, что во втором случае модель работает в 10 раз лучше. Поэтому было бы удобно, если бы она могла работать со вмеми положительными числами. Тут-то нам и поможет логарифм (мы будем использовать натуральный логарифм). Напомню, что график натурального логарифма выглядит следующим образом: . x = torch.arange(0,5,0.0001) fig, ax = plt.subplots() ax.grid(True) ax.plot(x, torch.log(x)) . [&lt;matplotlib.lines.Line2D at 0x20b485a6a48&gt;] . На отрезке от 0 до 1 логарифм принимает значения от -∞ до 0. Если умножить логарифм на -1, то мы будем иметь дело со всеми положительными значениями, что нам и нужно. . Итак, улучшим нашу функцию потерь: . cross_entropy = -torch.log(smx_preds[ndxs,targ]).mean() print(cross_entropy) . tensor(1.0860) . Такая функция потерь называется CrossEntropyLoss. Интересное замечание: градиент от CrossEntropyLoss(preds, targ) равен softmax(preds)-targ. То есть градиент прямо пропорционален удаленности предсказания от правильного ответа. . CrossEntropyLoss используется в задачах классификации, когда нам по сути нужно выбрать ответ из нескольких заранее установленных значений - классов. Если же перед нами стоит задача регрессии, то есть нам надо предсказать вещественное число (перед нами нет вариантов, ответ может быть любым на непрерывной числовой оси), тогда используется среднеквадратичная функция потерь - MSE, Mean Squared Error. Она задается следующей формулой: . mse_loss = ((preds-targ)**2).mean().squared() . Последнее, что хотелось бы обговорить. Сколько входных данных лучше давать модели, чтобы проверять качество предсказаний и корректировать параметры? Если мы отдадим ей сразу весь датасет, то она будет очень долго его обрабатывать. Если же мы будем передавать по одной картинке, то изменения будут очень нестабильны и не очень информативны, ведь параметры будут меняться после каждого входного значения. Кроме того, в этом случае подсчеты на GPU не дадут никакого выигрыша в произодительности, ведь графический процессор должен быть полностью загружен, чтобы распараллеливание задач имело смысл. Идеальный вариант, как всегда, по середине. Обычно весь датасет делят на несколько небольших наборов входных данных (mini-batches), по очереди загружают их в модель и берут среднее значение функции потерь по каждому набору. Когда все мини-наборы прошли через цикл модель-функция потерь-корректировка параметров, говорят, что прошла одна эпоха. Выбор размера этих небольших наборов (количества данных в каждом наборе) тоже ответственная задача: чем больше их размер, тем точнее и стабильнее оценка потерь, но тем дольше обучение. Размер должен быть таким, чтобы обеспечивать достаточную нагрузку на GPU и чтобы обучение проходило быстро и точно. . Базовые этапы обучения модели разобраны, осталось объединить их в единое целое. Повторим еще раз, как должно происходить обучение модели. . Задаем параметры - мы можем задать их случайным образом, нам в любом случае их менять, поэтому нет смысла тратить много времени, чтобы попробовать их изначально подобрать. | Прогоняем мини-набор входных данных через модель, получаем предсказания. | Применяем функцию активации к предсказаниям и вычисляем значение функции потерь - смотрим, насколько хороша наша модель; если устраивает - переходим к пункту 5. | Изменяем параметры на основе градиента функции потерь, переходим к пункту 2. | Оканчиваем обучение, сохраняем параметры. | &#1057;&#1086;&#1073;&#1080;&#1088;&#1072;&#1077;&#1084; &#1074; &#1077;&#1076;&#1080;&#1085;&#1086;&#1077; &#1094;&#1077;&#1083;&#1086;&#1077; . Для обучения модели будем использовать классический датасет с цифрами MNIST. Загрузим его: . #загружаем датасет path = untar_data(URLs.MNIST) #для дальнейшего удобства делаем путь к этому датасету базовым Path.BASE_PATH = path #посмотрим, что внутри скачанной папки path.ls() . (#2) [Path(&#39;testing&#39;),Path(&#39;training&#39;)] . Датасет состоит из двух частей: training - для обучения и testing - для оценки точности модели на данных, которые модель до этого не видела. . #сейчас нам нужна папка training, посмотрим, что в ней (path/&#39;training&#39;).ls() . (#10) [Path(&#39;training/0&#39;),Path(&#39;training/1&#39;),Path(&#39;training/2&#39;),Path(&#39;training/3&#39;),Path(&#39;training/4&#39;),Path(&#39;training/5&#39;),Path(&#39;training/6&#39;),Path(&#39;training/7&#39;),Path(&#39;training/8&#39;),Path(&#39;training/9&#39;)] . Внутри 10 папок с изображениями для каждой цифры. Сохраним в отдельные переменные для каждой цифры набор путей до ее изображений. . zeroes = (path/&#39;training&#39;/&#39;0&#39;).ls() ones = (path/&#39;training&#39;/&#39;1&#39;).ls() twos = (path/&#39;training&#39;/&#39;2&#39;).ls() threes = (path/&#39;training&#39;/&#39;3&#39;).ls() fours = (path/&#39;training&#39;/&#39;4&#39;).ls() fives = (path/&#39;training&#39;/&#39;5&#39;).ls() sixes = (path/&#39;training&#39;/&#39;6&#39;).ls() sevens = (path/&#39;training&#39;/&#39;7&#39;).ls() eigths = (path/&#39;training&#39;/&#39;8&#39;).ls() nines = (path/&#39;training&#39;/&#39;9&#39;).ls() #посмотрим, что лежит теперь, например, в переменной zeroes zeroes . (#5923) [Path(&#39;training/0/1.png&#39;),Path(&#39;training/0/1000.png&#39;),Path(&#39;training/0/10005.png&#39;),Path(&#39;training/0/10010.png&#39;),Path(&#39;training/0/10022.png&#39;),Path(&#39;training/0/10025.png&#39;),Path(&#39;training/0/10026.png&#39;),Path(&#39;training/0/10045.png&#39;),Path(&#39;training/0/10069.png&#39;),Path(&#39;training/0/10071.png&#39;)...] . Как мы и думали, в каждой папке полно изображений цифр. Например, для нуля там 5923 картинки. Давайте возьмем одну для примера и посмотрим, как она выглядит. . im0 = Image.open(zeroes[0]) im0 . Так как все картинки черно-белые, что они хранятся как матрица чисел, где каждый элемент матрицы - значение яркости соответствующего пикселя. Каждая картинка в датасете имеет размер 28 на 28 пикселей. Черный цвет задается нулем, белый - 255. Чтобы в этом убедиться, давайте посмотрим на кусочек картинки в числовом варианте: . #представим картинку как массив и возьмем кусочек из левого #верхнего угла (немного сдвинутый, иначе захватится только черный квадрат) array(im0)[1:20,5:15] . array([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 48], [ 0, 0, 0, 0, 0, 0, 0, 0, 54, 227], [ 0, 0, 0, 0, 0, 0, 10, 60, 224, 252], [ 0, 0, 0, 0, 0, 0, 163, 252, 252, 252], [ 0, 0, 0, 0, 0, 51, 238, 253, 253, 190], [ 0, 0, 0, 0, 48, 238, 252, 252, 179, 12], [ 0, 0, 0, 38, 165, 253, 233, 208, 84, 0], [ 0, 0, 7, 178, 252, 240, 71, 19, 28, 0], [ 0, 0, 57, 252, 252, 63, 0, 0, 0, 0], [ 0, 0, 198, 253, 190, 0, 0, 0, 0, 0], [ 0, 76, 246, 252, 112, 0, 0, 0, 0, 0], [ 0, 85, 252, 230, 25, 0, 0, 0, 0, 0], [ 0, 85, 252, 223, 0, 0, 0, 0, 0, 0], [ 0, 85, 252, 145, 0, 0, 0, 0, 0, 0], [ 0, 86, 253, 225, 0, 0, 0, 0, 0, 0]], dtype=uint8) . К слову, довольно красиво это можно отобразить с библиотекой Pandas. . import pandas as pd df = pd.DataFrame(tensor(im0)) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;gray&#39;) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 51 | 159 | 253 | 159 | 50 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 48 | 238 | 252 | 252 | 252 | 237 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 54 | 227 | 253 | 252 | 239 | 233 | 252 | 57 | 6 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 10 | 60 | 224 | 252 | 253 | 252 | 202 | 84 | 252 | 253 | 122 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 163 | 252 | 252 | 252 | 253 | 252 | 252 | 96 | 189 | 253 | 167 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 51 | 238 | 253 | 253 | 190 | 114 | 253 | 228 | 47 | 79 | 255 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 48 | 238 | 252 | 252 | 179 | 12 | 75 | 121 | 21 | 0 | 0 | 253 | 243 | 50 | 0 | 0 | 0 | 0 | 0 | . 11 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 38 | 165 | 253 | 233 | 208 | 84 | 0 | 0 | 0 | 0 | 0 | 0 | 253 | 252 | 165 | 0 | 0 | 0 | 0 | 0 | . 12 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 178 | 252 | 240 | 71 | 19 | 28 | 0 | 0 | 0 | 0 | 0 | 0 | 253 | 252 | 195 | 0 | 0 | 0 | 0 | 0 | . 13 0 | 0 | 0 | 0 | 0 | 0 | 0 | 57 | 252 | 252 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 253 | 252 | 195 | 0 | 0 | 0 | 0 | 0 | . 14 0 | 0 | 0 | 0 | 0 | 0 | 0 | 198 | 253 | 190 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 255 | 253 | 196 | 0 | 0 | 0 | 0 | 0 | . 15 0 | 0 | 0 | 0 | 0 | 0 | 76 | 246 | 252 | 112 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 253 | 252 | 148 | 0 | 0 | 0 | 0 | 0 | . 16 0 | 0 | 0 | 0 | 0 | 0 | 85 | 252 | 230 | 25 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 135 | 253 | 186 | 12 | 0 | 0 | 0 | 0 | 0 | . 17 0 | 0 | 0 | 0 | 0 | 0 | 85 | 252 | 223 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 131 | 252 | 225 | 71 | 0 | 0 | 0 | 0 | 0 | 0 | . 18 0 | 0 | 0 | 0 | 0 | 0 | 85 | 252 | 145 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 48 | 165 | 252 | 173 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 19 0 | 0 | 0 | 0 | 0 | 0 | 86 | 253 | 225 | 0 | 0 | 0 | 0 | 0 | 0 | 114 | 238 | 253 | 162 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 20 0 | 0 | 0 | 0 | 0 | 0 | 85 | 252 | 249 | 146 | 48 | 29 | 85 | 178 | 225 | 253 | 223 | 167 | 56 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 21 0 | 0 | 0 | 0 | 0 | 0 | 85 | 252 | 252 | 252 | 229 | 215 | 252 | 252 | 252 | 196 | 130 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 22 0 | 0 | 0 | 0 | 0 | 0 | 28 | 199 | 252 | 252 | 253 | 252 | 252 | 233 | 145 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 23 0 | 0 | 0 | 0 | 0 | 0 | 0 | 25 | 128 | 252 | 253 | 252 | 141 | 37 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 24 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 25 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 26 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 27 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . Создадим для каждой цифры один большой массив: соберем все картинки в качестве числовых массивов в один массив. . zeroes_tensors = [tensor(Image.open(o)) for o in zeroes] ones_tensors = [tensor(Image.open(o)) for o in ones] twos_tensors = [tensor(Image.open(o)) for o in twos] threes_tensors = [tensor(Image.open(o)) for o in threes] fours_tensors = [tensor(Image.open(o)) for o in fours] fives_tensors = [tensor(Image.open(o)) for o in fives] sixes_tensors = [tensor(Image.open(o)) for o in sixes] sevens_tensors = [tensor(Image.open(o)) for o in sevens] eigths_tensors = [tensor(Image.open(o)) for o in eigths] nines_tensors = [tensor(Image.open(o)) for o in nines] . Сейчас у нас для каждой цифры массив тензоров, но для более удобного доступа к значениям будет лучше иметь один тензор 3 ранга. В этом нам поможет метод stack(). Сейчас у нас в тензоре только целые числа от 0 до 255, но с целыми числами не очень удобно работать, поскольку в итоге нам все равно придется иметь дело в вещественными числами, например, когда будем брать среднее значение функции потерь. Поэтому приведем все числа к вещественным значениям методом float(), ну и поскольку мы избавились от целых чисел, то будет гораздо лучше, если у нас будут храниться числа от 0 до 1. Для этого поделим все значения на 255. . stacked_zeroes = torch.stack(zeroes_tensors).float()/255 stacked_ones = torch.stack(ones_tensors).float()/255 stacked_twos = torch.stack(twos_tensors).float()/255 stacked_threes = torch.stack(threes_tensors).float()/255 stacked_fours = torch.stack(fours_tensors).float()/255 stacked_fives = torch.stack(fives_tensors).float()/255 stacked_sixes = torch.stack(sixes_tensors).float()/255 stacked_sevens = torch.stack(sevens_tensors).float()/255 stacked_eigths = torch.stack(eigths_tensors).float()/255 stacked_nines = torch.stack(nines_tensors).float()/255 #на всякий случай проверим размерность получившегося тензора и убедимся, что все хорошо stacked_zeroes.shape . torch.Size([5923, 28, 28]) . Мы будем загружать в модель не отдельные цифры, а все вместе, поэтому объединим все цифры в один тензор, для этого используем метод cat(). Кроме того нам вообще-то не нужно представлять каждую картинку как матрицу 28х28, а гораздо удобнее будет &quot;выстроить все пиксели в один ряд&quot;, то есть представить картинку как массив длиной 784 (=28^2). Тогда наш тензор 3 ранга превращается в тензор 2 ранга, для этого есть метод view(), который мы вызовем с параметрами view(-1,28*28), что означает, что существующий тензор должен перегруппироваться так, чтобы вторая размерность была 784, а первая - подбирается исходя из известных размерностей. . train_x = torch.cat([stacked_zeroes, stacked_ones, stacked_twos, stacked_threes, stacked_fours, stacked_fives, stacked_sixes, stacked_sevens, stacked_eigths, stacked_nines]).view(-1,28*28) #проверим размерность train_x.shape . torch.Size([60000, 784]) . Так как для обучения нам нужен помеченный датасет, сформируем массив ответов к нашему датасету. Это будет массив с таким количеством нулей, сколько у нас картинок с нулями, затем идет такое количество единиц, сколько в датасете картинок с единицами и так далее. Ну и так как размерность должна соответствовать размерности входных данных, то есть быть 60000х1, а не наоборот, то применим метод unsqueeze(). . train_y = tensor([0]*len(zeroes)+[1]*len(ones)+[2]*len(twos)+[3]*len(threes)+[4]*len(fours)+[5]*len(fives)+[6]*len(sixes)+[7]*len(sevens)+[8]*len(eigths)+[9]*len(nines)).unsqueeze(1) #проверим размерность train_y.shape . torch.Size([60000, 1]) . #формируем итоговый датасет: связываем соответствующие друг другу картинки и ответы. dset = list(zip(train_x,train_y)) #возьмем первый элемент датасета и проверим, что размерность картинки верная, и ответ к ней 0 x,y = dset[0] x.shape,y . (torch.Size([784]), tensor([0])) . #так как нам понадобится потом делить датасет на мини-наборы, удобно воспользоваться #структурой DataLoader, которая уже есть в библиотеке fastai. #размер этого мини-набора укажем 128 dl = DataLoader(dset, batch_size = 128) #возьмем первый мини-набор и убедимся, что в нем 256 картинок и 256 ответов к ним xf,yf = first(dl) xf.shape, yf.shape . (torch.Size([128, 784]), torch.Size([128, 1])) . Все то же самое необходимо теперь проделать и для валидационной выборки из папки testing. . valid_0_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;0&#39;).ls()]).float()/255 valid_1_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;1&#39;).ls()]).float()/255 valid_2_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;2&#39;).ls()]).float()/255 valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;3&#39;).ls()]).float()/255 valid_4_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;4&#39;).ls()]).float()/255 valid_5_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;5&#39;).ls()]).float()/255 valid_6_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;6&#39;).ls()]).float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;7&#39;).ls()]).float()/255 valid_8_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;8&#39;).ls()]).float()/255 valid_9_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;9&#39;).ls()]).float()/255 #посмотрим размерность valid_0_tens.shape . torch.Size([980, 28, 28]) . #точно так же формируем датасет valid_x = torch.cat([valid_0_tens, valid_1_tens, valid_2_tens, valid_3_tens, valid_4_tens, valid_5_tens, valid_6_tens, valid_7_tens, valid_8_tens, valid_9_tens]).view(-1,28*28) valid_y = tensor([0]*len(valid_0_tens)+[1]*len(valid_1_tens)+[2]*len(valid_2_tens)+[3]*len(valid_3_tens)+[4]*len(valid_4_tens)+[5]*len(valid_5_tens)+[6]*len(valid_6_tens)+[7]*len(valid_7_tens)+[8]*len(valid_8_tens)+[9]*len(valid_9_tens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) #проверим размерность valid_x.shape, valid_y.shape . (torch.Size([10000, 784]), torch.Size([10000, 1])) . #так же с помощью DataLoader разбиваем на мини-батчи valid_dl = DataLoader(valid_dset, batch_size=128) . Данные готовы, теперь приступаем к непосредственному обучению модели. Вспоминаем те 5 пунктов, по которым проходит обучение: . 1: Задаем параметры. . #функция для генерации рандомных параметров заданной размерностью size def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . #задаем веса weights = init_params((28*28,10)) #задаем сдвиги bias = init_params(10) #объединим параметры в одну переменную params = weights, bias . 2: Прогоняем данные через модель. . #задаем линейный слой, из которого и состоит наша модель def linear1(x): return x@weights + bias . #прогоним пока только первый мини-набор preds = linear1(xf) preds, preds.shape . (tensor([[ 1.8653, -12.6038, 2.8638, ..., -2.0845, -6.3622, 10.4594], [ -3.7797, -7.0354, 3.4648, ..., 4.4722, 0.5934, 7.8434], [ 13.5319, -8.1645, -0.5384, ..., 1.0122, -7.8068, 20.1998], ..., [ -0.4584, -14.6027, 7.5739, ..., -2.2108, -11.9117, 10.6609], [ 2.7176, -6.2564, 0.4641, ..., -2.1251, -6.5700, 11.8143], [ -1.8461, -8.9604, -9.6538, ..., 1.7477, 3.5221, 13.6536]], grad_fn=&lt;AddBackward0&gt;), torch.Size([128, 10])) . 3: Применяем функцию активации и вычисляем значение функции потерь. . def softmax(x): return torch.exp(x) / torch.exp(x).sum(dim=1, keepdim=True) . def cross_entropy_loss(inputs, targets): smx_preds = softmax(inputs) return -torch.log(smx_preds[range(len(inputs)),targets.squeeze(1)]).mean() . loss = cross_entropy_loss(preds, yf) loss . tensor(9.0224, grad_fn=&lt;NegBackward&gt;) . 4: Считаем градиент и изменяем параметры. . #считаем градиент loss.backward() . #задаем темп обучения lr = 0.001 #изменяем параметры for p in params: p.data -= p.grad * lr #после того, как мы взяли значение градиента, его необходимо обнулить, #иначе в следующий раз градиент добавится к текущему значению! p.grad.zero_() . Соберем из всего, что у нас есть, отдельную функцию. . def train_epoch(model, dl, lr, params): #проходимся по всем мини-батчам for xb,yb in dl: #получаем предсказания preds = model(xb) #считаем функцию потерь loss = cross_entropy_loss(preds, yb) #считаем градиент loss.backward() #изменяем веса for p in params: p.data -= p.grad*lr p.grad.zero_() . Поскольку значение функции потерь мы никак интерпретировать не можем, стоит добавить понятную для человека метрику, например, точность, т.е. отношение правильно определенных картинок к общему количеству изображений. . #определим точность одного мини-набора def batch_accuracy(ans,yb): preds = softmax(ans) #берем класс, вероятность принадлежности к которому наибольшая, и сравниваем с правильным ответом #в итоге получаем массив булевых значений correct = torch.argmax(preds,dim=1).unsqueeze(1) == yb #переводим булевы значения в числовые, получаем массив из нулей(False) и единиц(True). #чтобы найти количество верных ответов, то есть количество единиц, можно просто все просуммировать. #получается, что точность можно подсчитать как среднее арифметическое return correct.float().mean() . #определим точность на всем датасете def validate_epoch(model, valid_dl): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(),4) . Один проход всего датасета через цикл - одна эпоха - будет выглядеть так: . lr = 0.01 train_epoch(linear1, dl, lr, params) #точность модели на валидационной выборке validate_epoch(linear1, valid_dl) . 0.2441 . Теперь осталось задать количество эпох и запустить процесс обучения. . epochs = 80 lr = 0.01 for i in range(epochs): train_epoch(linear1, dl, lr, params) print(validate_epoch(linear1, valid_dl), end=&#39; &#39;) . 0.3517 0.435 0.4989 0.5426 0.5813 0.6098 0.6299 0.652 0.6676 0.6809 0.692 0.7014 0.7106 0.7193 0.7267 0.7335 0.7413 0.7473 0.7532 0.7586 0.7632 0.7668 0.7697 0.7745 0.7778 0.7813 0.7854 0.7876 0.7897 0.7921 0.7948 0.7973 0.7985 0.8011 0.8025 0.8044 0.8051 0.8072 0.8096 0.8112 0.8134 0.8152 0.8163 0.8176 0.8189 0.8205 0.821 0.8223 0.824 0.8249 0.8264 0.8275 0.8287 0.8299 0.8306 0.8319 0.833 0.8343 0.835 0.836 0.8366 0.8375 0.8382 0.8384 0.8394 0.84 0.8408 0.8412 0.8419 0.8423 0.8433 0.8439 0.8446 0.8453 0.8456 0.8459 0.8465 0.8471 0.8476 0.848 . Итак, мы достигли неплохой точности, почти 85%. Если есть желание, можно поиграться с темпом обучения, количеством эпох, размером мини-батчей и посмотреть, как будет меняться скорость обучения. Можно попробовать дообучать модель, чтобы получить лучшую точность. . Мои поздравления! Мы написали простейшую модель, которую можно обучить, с нуля своими руками! Конечно, не стоит каждый раз писать это все самому, ведь все готовые функции уже есть в библиотеках. Но всегда важно понимать, что представляет собой функция, которую ты используешь. . Вообще, не очень хорошо, что у нас параметры являются глобальными переменными, это может вызвать огромное множество проблем. Поэтому было бы неплохо написать специальный класс, хранящий параметры как свойства. . class BasicOptim: def __init__(self, params, lr): self.params = list(params) self.lr = lr def step(self): for p in self.params: p.data -= p.grad.data*self.lr def zero_grad(self): for p in self.params: p.grad = None . #в качестве модели возьмем библиотечный модуль Linear, который просто объединяет в себе методы linear1() и init_params() linear_model = torch.nn.Linear(28*28, 10) #создаем объект класса opt = BasicOptim(linear_model.parameters(), 0.01) . #одна эпоха будет выглядеть так: def train_epoch2(model, dl): for xb,yb in dl: preds = model(xb) loss = cross_entropy_loss(preds, yb) loss.backward() opt.step() opt.zero_grad() . #весь процесс обучения будет выглядеть следующим образом: def train_model2(model, dl, epochs): for i in range(epochs): train_epoch2(model, dl) print(validate_epoch(model, valid_dl), end=&#39; &#39;) . train_model2(linear_model, dl, 80) . 0.1109 0.2526 0.4114 0.4962 0.5539 0.5929 0.6246 0.6506 0.6702 0.6876 0.7027 0.7175 0.731 0.7407 0.7493 0.7592 0.7683 0.7762 0.7806 0.7855 0.7909 0.7955 0.8003 0.8049 0.8082 0.8115 0.8148 0.8172 0.8197 0.8215 0.8249 0.8265 0.8284 0.8306 0.8326 0.834 0.8352 0.8375 0.8394 0.8408 0.8423 0.8439 0.8451 0.8461 0.8465 0.8475 0.8486 0.8499 0.8506 0.8515 0.8525 0.8531 0.8542 0.8558 0.8561 0.8563 0.8571 0.8574 0.8581 0.8588 0.8596 0.8601 0.8604 0.8615 0.8615 0.862 0.8623 0.8625 0.863 0.8635 0.8642 0.8645 0.8652 0.8658 0.866 0.8662 0.8665 0.8665 0.8668 0.8673 . &#1054;&#1090; &#1086;&#1076;&#1085;&#1086;&#1075;&#1086; &#1089;&#1083;&#1086;&#1103; &#1082; &#1089;&#1077;&#1090;&#1080; . Буквально последнее замечание на сегодня. Мы разобрались с линейным слоем, но нейросети состоят из нескольких слоев. Казалось бы, мы можем вставить несколько линейных слоев друг за другом и радоваться жизни. Но нельзя забывать, что комбинация линейных преобразований дает линейное преобразование. Другими словами, несколько подряд идущих линейных слоев можно заменить одним линейным слоем. Поэтому для увеличения количества слоев между линейными слоями надо добавить нелинейность. Одной из таких нелинейнойстей является функция ReLU (Rectified Linear Unit). Название ее звучит страшно, но на деле она просто заменяет все отрицательные значения на 0, задается короткой формулой f(x) = max(0,x) и выглядит следующим образом: . x = torch.arange(-4,4,0.1) plt.plot(x, F.relu(x)) . [&lt;matplotlib.lines.Line2D at 0x20b4300a308&gt;] . Тогда сеть из двух слоев будет выглядеть так: . def simple_net(x): res = x@w1+b1 res = res.max(tensor(0.0)) res = res@w2+b2 return res . #задаем веса для двух слоев, размер второго слоя может быть любым, я поставила 30 w1 = init_params((28*28,30), torch.sqrt(torch.tensor(1./30))) b1 = init_params(30, torch.sqrt(torch.tensor(1./30))) w2 = init_params((30,10),torch.sqrt(torch.tensor(1./10))) b2 = init_params(10, torch.sqrt(torch.tensor(1./10))) params = w1,b1,w2,b2 . epochs = 80 lr = 0.001 for i in range(epochs): train_epoch(simple_net, dl, lr, params) print(validate_epoch(simple_net, valid_dl), end=&#39; &#39;) . 0.1421 0.2243 0.2989 0.368 0.4282 0.4835 0.5274 0.5631 0.5937 0.6178 0.6372 0.6525 0.6689 0.6825 0.6933 0.7061 0.7146 0.7252 0.7332 0.7419 0.7484 0.7546 0.76 0.765 0.7713 0.7761 0.7803 0.7854 0.7892 0.7939 0.797 0.8011 0.8038 0.8067 0.8101 0.8122 0.8142 0.8167 0.8187 0.8213 0.8236 0.8251 0.8272 0.8287 0.831 0.8333 0.8347 0.8365 0.8384 0.8399 0.8412 0.8433 0.8444 0.8458 0.847 0.8481 0.8485 0.8494 0.8504 0.8514 0.8529 0.854 0.8555 0.8564 0.8573 0.8587 0.8596 0.86 0.8607 0.8613 0.8619 0.8625 0.8637 0.8645 0.8656 0.8664 0.867 0.8682 0.8691 0.8698 . Или тоже самое, но с библиотечными функциями: . simple_net = nn.Sequential( nn.Linear(28*28,30), nn.ReLU(), nn.Linear(30,10) ) . dls = DataLoaders(dl, valid_dl) learn = Learner(dls, simple_net, opt_func=SGD, loss_func=cross_entropy_loss, metrics=batch_accuracy) . learn.fit(80, 0.001) . epoch train_loss valid_loss batch_accuracy time . 0 | 2.323066 | 2.242063 | 0.107600 | 00:01 | . 1 | 2.238540 | 2.170549 | 0.150900 | 00:01 | . 2 | 2.149217 | 2.081092 | 0.184200 | 00:01 | . 3 | 2.051738 | 1.976882 | 0.249500 | 00:01 | . 4 | 1.936565 | 1.857309 | 0.400200 | 00:02 | . 5 | 1.803392 | 1.730667 | 0.542100 | 00:01 | . 6 | 1.657574 | 1.606008 | 0.577500 | 00:01 | . 7 | 1.514135 | 1.488725 | 0.585600 | 00:01 | . 8 | 1.384189 | 1.381572 | 0.594500 | 00:01 | . 9 | 1.271495 | 1.285586 | 0.612000 | 00:01 | . 10 | 1.175573 | 1.200758 | 0.631400 | 00:01 | . 11 | 1.093912 | 1.126690 | 0.649600 | 00:01 | . 12 | 1.024183 | 1.062356 | 0.666400 | 00:01 | . 13 | 0.964618 | 1.006377 | 0.680200 | 00:01 | . 14 | 0.913387 | 0.957478 | 0.695300 | 00:01 | . 15 | 0.869053 | 0.914575 | 0.706300 | 00:01 | . 16 | 0.830513 | 0.876644 | 0.716900 | 00:01 | . 17 | 0.796775 | 0.842871 | 0.727100 | 00:01 | . 18 | 0.766970 | 0.812626 | 0.737200 | 00:01 | . 19 | 0.740425 | 0.785390 | 0.745000 | 00:01 | . 20 | 0.716652 | 0.760729 | 0.751300 | 00:01 | . 21 | 0.695254 | 0.738267 | 0.757400 | 00:01 | . 22 | 0.675916 | 0.717681 | 0.763500 | 00:01 | . 23 | 0.658293 | 0.698764 | 0.770000 | 00:01 | . 24 | 0.642227 | 0.681287 | 0.775500 | 00:01 | . 25 | 0.627441 | 0.665121 | 0.780500 | 00:01 | . 26 | 0.613840 | 0.650098 | 0.786200 | 00:02 | . 27 | 0.601233 | 0.636105 | 0.790900 | 00:01 | . 28 | 0.589547 | 0.623015 | 0.795700 | 00:01 | . 29 | 0.578655 | 0.610785 | 0.799400 | 00:01 | . 30 | 0.568515 | 0.599315 | 0.803200 | 00:01 | . 31 | 0.559012 | 0.588529 | 0.807000 | 00:01 | . 32 | 0.550153 | 0.578342 | 0.812000 | 00:01 | . 33 | 0.541832 | 0.568746 | 0.814600 | 00:01 | . 34 | 0.533982 | 0.559708 | 0.817500 | 00:01 | . 35 | 0.526607 | 0.551148 | 0.822200 | 00:01 | . 36 | 0.519648 | 0.543041 | 0.824900 | 00:01 | . 37 | 0.513086 | 0.535341 | 0.827400 | 00:01 | . 38 | 0.506886 | 0.528042 | 0.830100 | 00:01 | . 39 | 0.501001 | 0.521115 | 0.833000 | 00:01 | . 40 | 0.495454 | 0.514530 | 0.835700 | 00:01 | . 41 | 0.490194 | 0.508235 | 0.836900 | 00:01 | . 42 | 0.485196 | 0.502251 | 0.838800 | 00:01 | . 43 | 0.480438 | 0.496552 | 0.841500 | 00:01 | . 44 | 0.475901 | 0.491104 | 0.843600 | 00:01 | . 45 | 0.471596 | 0.485900 | 0.846000 | 00:01 | . 46 | 0.467501 | 0.480927 | 0.847800 | 00:01 | . 47 | 0.463562 | 0.476178 | 0.850100 | 00:01 | . 48 | 0.459790 | 0.471635 | 0.851900 | 00:01 | . 49 | 0.456175 | 0.467279 | 0.853600 | 00:01 | . 50 | 0.452724 | 0.463090 | 0.855500 | 00:01 | . 51 | 0.449434 | 0.459058 | 0.856900 | 00:01 | . 52 | 0.446276 | 0.455192 | 0.858500 | 00:01 | . 53 | 0.443211 | 0.451484 | 0.860400 | 00:01 | . 54 | 0.440251 | 0.447927 | 0.861000 | 00:01 | . 55 | 0.437380 | 0.444495 | 0.862000 | 00:01 | . 56 | 0.434640 | 0.441173 | 0.862500 | 00:01 | . 57 | 0.432018 | 0.437973 | 0.864000 | 00:01 | . 58 | 0.429457 | 0.434893 | 0.865400 | 00:01 | . 59 | 0.426991 | 0.431904 | 0.866000 | 00:01 | . 60 | 0.424628 | 0.429025 | 0.866800 | 00:01 | . 61 | 0.422321 | 0.426243 | 0.867600 | 00:01 | . 62 | 0.420124 | 0.423549 | 0.868700 | 00:01 | . 63 | 0.417955 | 0.420956 | 0.870200 | 00:01 | . 64 | 0.415857 | 0.418443 | 0.870800 | 00:01 | . 65 | 0.413843 | 0.416004 | 0.871700 | 00:01 | . 66 | 0.411870 | 0.413658 | 0.872600 | 00:01 | . 67 | 0.409954 | 0.411381 | 0.873600 | 00:01 | . 68 | 0.408086 | 0.409178 | 0.874200 | 00:01 | . 69 | 0.406274 | 0.407028 | 0.874600 | 00:01 | . 70 | 0.404499 | 0.404941 | 0.875100 | 00:01 | . 71 | 0.402768 | 0.402916 | 0.875900 | 00:01 | . 72 | 0.401081 | 0.400941 | 0.877000 | 00:01 | . 73 | 0.399435 | 0.399008 | 0.877700 | 00:01 | . 74 | 0.397830 | 0.397143 | 0.878200 | 00:01 | . 75 | 0.396295 | 0.395319 | 0.878700 | 00:01 | . 76 | 0.394802 | 0.393540 | 0.879900 | 00:01 | . 77 | 0.393287 | 0.391817 | 0.880900 | 00:01 | . 78 | 0.391850 | 0.390129 | 0.881700 | 00:01 | . 79 | 0.390432 | 0.388492 | 0.882200 | 00:01 | . Ну вот и все на сегодня. Статья получилась очень объемной и насыщенной, но, надеюсь, она вам понравилась. Как обычно, все вопросы и замечания жду в комментариях. До новых встреч) .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2021/08/27/what-a-number.html",
            "relUrl": "/fastpages/jupyter/2021/08/27/what-a-number.html",
            "date": " • Aug 27, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Хочу делиться",
            "content": "После того, как ты обучил модель, которая показывает хорошие результаты, всегда хочется поделиться этой радостью с окружающими, хочется сказать: &quot;Смотри, у меня есть модель, которая может сказать, кто на картинке: кошка или собака. Хочешь попробовать? Вот загрузи фотографию своей Мурки&quot;. Но делать клиент-серверное приложение с крутым дизайном очень лень, на это ты потратишь больше времени, чем на саму модель. Что же делать? Не отправлять же всем свой код, в самом деле! Выход есть! Нам поможет... Подождите, давайте все сделаем попорядку. . &#1054;&#1073;&#1091;&#1095;&#1072;&#1077;&#1084; &#1084;&#1086;&#1076;&#1077;&#1083;&#1100; . В этой статье у меня нет цели рассказать вам в подробностях, как обучать модель, цель этой статьи - показать, как быстро получить из модели готовое приложение. Поэтому на этом разделе не буду долго задерживаться. Итак, обучение модели. Поехали! . Сначала импортируем библиотеку. Раскомментируйте первую ячейку, если у вас еще не установлен fastai или установлена старая версия. . #!pip uninstall fastai #!pip install fastai . from fastai.vision.all import * from fastai.vision.widgets import * . Теперь возьмем уже существующий датасет с кошками и собаками, который нам предоставляет эта библиотека, и загрузим его на свою машину: . path = untar_data(URLs.PETS) path . Path(&#39;/root/.fastai/data/oxford-iiit-pet&#39;) . Метод untar_data, как я уже сказала, скачивает датасет на сервер, где производятся вычисления: если вы считаете на локальном компьютере, то скачивает на ваш локальный компьютер, если вы считаете где-нибудь на Colab или Gradient, то на ту виртуальную машину и загружает. Затем этот метод распаковывает архив, если данные заархивированы, и возвращает путь, где лежат конечные данные. Давайте посмотрим, что лежит внутри загруженной папки: . Path.BASE_PATH = path path.ls() . (#2) [Path(&#39;annotations&#39;),Path(&#39;images&#39;)] . Вы видели, какой у нас длинный путь, в котором лежит датасет. Чтобы не отображать его каждый раз, в первой строчке мы сделали адрес этой папки базовым. Таким образом, когда мы с помощью метода ls() отображаем содержимое папки, мы видим пути относительно этого базового адреса. Итак, у нас внутри две папки: annotations и images. Папка annotations нас не интересует - там лежат данные для определения конкретного места на картинке, где изображены животные. Нас интересует папка images. Давайте заглянем в нее: . path = path/&#39;images&#39; path.ls() . (#7393) [Path(&#39;images/samoyed_21.jpg&#39;),Path(&#39;images/newfoundland_48.jpg&#39;),Path(&#39;images/wheaten_terrier_139.jpg&#39;),Path(&#39;images/leonberger_1.jpg&#39;),Path(&#39;images/samoyed_175.jpg&#39;),Path(&#39;images/miniature_pinscher_110.jpg&#39;),Path(&#39;images/german_shorthaired_3.jpg&#39;),Path(&#39;images/wheaten_terrier_131.jpg&#39;),Path(&#39;images/pomeranian_123.jpg&#39;),Path(&#39;images/Egyptian_Mau_77.jpg&#39;)...] . Все верно. В папке images лежат 7393 изображения с кошками и собаками различных пород. Если мы внимательно посмотрим на названия картинок, то увидим, что это названия пород. А если посмотрим еще более внимательно, то увидим, что породы кошек написаны с большой буквы, а собак - с маленькой. Ну или можно было получить эту информацию с сайта, с которого мы скачали наши данные:) Породы нам пока не нужны, а вот принцип отделения кошек от собак полезен. Оформим его в виде отдельного метода: . def cat_or_dog(x): return &#39;Cat&#39; if x[0].isupper() else &#39;Dog&#39; . Загрузим наши данные таким образом, чтобы они представляли собой структуру, удобную для дальнейшей обработки. В этом нам поможет класс ImageDataLoaders: . dls = ImageDataLoaders.from_name_func(path, get_image_files(path), valid_pct = 0.2, seed = 42, label_func = cat_or_dog, item_tfms = Resize(224)) . Если вы читали мой пост, в котором я рассказывала об основных понятиях нейронных сетей, то вы быстро поймете, что здесь произошло, а если нет, то предлагаю вам быстренько с ним ознакомиться. Итак, разбираем построчно. dls - переменная, в которой будет храниться структура из наших изображений. ImageDataLoaders - собственно класс, который эту структуру представляет. Эта структура удобна тем, что в ней хранится информация, откуда брать таргеты (labels) для изображений, откуда брать сами изображения, как их делить на тренировочные и валидационные выборки и многое другое. Собственно, функция from_name_func и показывает, что при создании загрузчика файлов(этой самой структуры), таргеты для каждого изображения будем брать из его имени. Функции передаем: . путь, откуда брать файлы; | функцию, показывающую, каким образом брать эти файлы (get_image_files - брать изображения рекурсивно из каждой подпапки); | valid_pct - какую часть от всех изображений выделить под валидационную выборку; | seed - ядро для рандома, чтобы в валидацонную выборку попали случайные изображения, но чтобы на каждой эпохе эта выборка была одной и той же; | label_func - задаем функцию, каким образом получить таргет. Помните, мы определили метод, определяющей по первой букве названия файла кошка перед нами или собака? Его мы и передадим. | item_tfms - какие преобразования проделать с каждым изображением. В данном случае просто преобразуем все изображения к одному размеру (224*224), чтобы можно было работать с ними на ГПУ. | . Как видите, ничего сложного. Делаем все необходимое, что написано в том посте, который я только что упомянула, буквально в одной строчке. Идем дальше. Данные готовы, что делаем с моделью? Возьмем предобученную модель и дообучаем ее на своих данных. Для нашей не самой сложной модели возьмем хорошую сеть из 34-ти слоев: ResNet34. . learner = cnn_learner(dls, resnet34, metrics=error_rate) . Метод cnn_learner строит сверточную нейронную сеть из наших данных и из предобученной модели. Мы можем передать ему большое число параметров, например, loss function, оптимизирующую функцию, шаг (learning rate) и так далее. Но сейчас мы передали ему только метрику, которую хотели бы использовать - error_rate (отношение количества ошибочных предсказаний к общему числу предсказаний). Кстати, если вы хотите подробнее узнать о той или иной функции, то можете использовать метод doc() или поставить ? или ?? перед именем функции. Попробуйте, это удобно! . doc(cnn_learner) . cnn_learner(dls, arch, loss_func=None, pretrained=True, cut=None, splitter=None, y_range=None, config=None, n_out=None, normalize=True, opt_func=&lt;function Adam at 0x7f27e8840378&gt;, lr=0.001, cbs=None, metrics=None, path=None, model_dir=&#39;models&#39;, wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95)) Build a convnet style learner from `dls` and `arch` To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev . ?cnn_learner . ??cnn_learner . Итак, нам остался последний шаг - собственно, само обучение. Вернее, дообучение модели на наших данных: . learner.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 0.122511 | 0.023786 | 0.005413 | 00:50 | . epoch train_loss valid_loss error_rate time . 0 | 0.060866 | 0.060334 | 0.014208 | 00:54 | . 1 | 0.040196 | 0.015185 | 0.004060 | 00:54 | . 2 | 0.018751 | 0.006086 | 0.002706 | 00:54 | . 3 | 0.009726 | 0.012300 | 0.002706 | 00:55 | . Дообучение модели иногда называют файнтьюнингом от английского термина fine-tune. Поэтому метод дообучения так и называется. В качестве параметра мы передаем число эпох. Например, 4. . 4 эпохи дали нам очень неплохой результат. Я удовольствуюсь им, а вы, если хотите, можете посмотреть, как будет изменяться точность с дальнейшим обучением. . Можем сохранить нашу модель, чтобы в следующий раз, когда она нам понадобится, нам не пришлось заново ее обучать. Есть 2 способа сохранить модель: . Можно сохранить только параметры, тогда при следующем использовании мы будем брать брать нужную нам архитектуру модели (в данном случае, resnet34) и передавать ей сохраненные параметры. | Можно сохранить сразу все: и параметры, и архитектуру, и при следующем использовании нам просто надо будет просто взять модель из сохраненного файла. | Как вы догадываетесь, в первом случае сохраненный файл весит гораздо меньше, но требуется чуть больше хлопот. Не будем пока заморачиваться и сохраним всю модель целиком, как в пункте 2: . learner.export(os.path.abspath(&#39;./export.pkl&#39;)) . Метод export сохраняет модель в файл с разрешением .pkl в текущую папку. По умолчанию имя файла будет &quot;export.pkl&quot;, но вы можете передать в метод другое имя или абсолютный путь. Проверим, что все сохранилось: . path = Path() path.ls(file_exts=&quot;.pkl&quot;) . (#1) [Path(&#39;export.pkl&#39;)] . Но если в Gradient ваша модель сохранится за вами, и вы снова увидите ее, если зайдете на следующий день, то с Colab-ом так, к сожалению, не прокатит. Зато с Colab удобно сохранять модель на гугл-диск. Для этого надо зайти на свой диск и выбрать место, куда сохранить: . from google.colab import drive drive.mount(&#39;/content/gdrive&#39;) . Mounted at /content/gdrive . learner.export(&#39;/content/gdrive/My Drive/export.pkl&#39;) . Можете проверить, на вашем Google диске должен появиться файл с расширением .pkl. . &#1048;&#1089;&#1087;&#1086;&#1083;&#1100;&#1079;&#1091;&#1077;&#1084; &#1075;&#1086;&#1090;&#1086;&#1074;&#1091;&#1102; &#1084;&#1086;&#1076;&#1077;&#1083;&#1100; . Теперь мы хотим загрузить полученную нами модель для дальнейшего использования. (Конечно, загружать модель в этом же блокноте нам сейчас особого смысла нет, но давайте представим, что мы создали новый jupyter-notebook и теперь работаем в нем. Кстати, вы можете именно так и поступить!) Чтобы загрузить модель, используем метод load_learner. . learner_s = load_learner(path/&#39;export.pkl&#39;) . Модель загружена. Давайте посмотрим, помнит ли она, на какие два класса она должна делить изображения. Обратимся к загрузчику классов и посмотрим, какие таргеты у него есть: . learner_s.dls.vocab . (#2) [&#39;Cat&#39;,&#39;Dog&#39;] . Отлично. Чтобы сделать предсказание, будем пользоваться методом predict. Но для начала давайте получим самый простой интерфейс для загрузки картинок и &quot;скармливания&quot; их нашей модели. Начинается самая интересная часть, ради которой и была написана эта статья. . IPython widgets . Для людей, не сильно любящих заниматься разработкой графического пользовательского интерфейса(GUI), существуют IPython widgets. Это GUI-компоненты, помогающие быстро и без особых трудностей создать простой пользовательский интерфейс прямо в jupyter notebook-е. Давайте посмотрим, что он умеет. . Создадим кнопку для загрузки изображения с локального компьютера. Самое прекрасное, что такая кнопка уже есть в виджетах и нам не придется писать для нее функционал самим. . btn_upload = widgets.FileUpload() btn_upload . Попробуйте загрузить какое-нибудь изображение. Чтобы его отобразить, выделим место, в котором будут отображаться загруженные картинки: . placeholder = widgets.Output() placeholder . Видите, мы его создали, но пока там пусто. Давайте отобразим там ваше загруженное изображение: . img = PILImage.create(btn_upload.data[-1]) with placeholder: display(img.to_thumb(250,250)) . Чтобы снова очистить это место, используем метод clear_output(): . placeholder.clear_output() . А теперь посмотрим, что скажет нам наша модель: . learner_s.predict(img) . (&#39;Cat&#39;, tensor(0), tensor([1.0000e+00, 1.6606e-11])) . Здорово! Нам выводится 3 значения: . Таргет (класс, к которому наша модель относит наше изображение) | Порядковый номер этого класса | Вероятности, с каким это изображение относится к каждому из классов | Давайте создадим специальное место, где будем отображать предсказание: . pred, ndx, probs = learner_s.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Предсказание: {pred}; Вероятность: {probs[ndx]:.04f}&#39; lbl_pred . Хочется, чтобы картинка и предсказания отображались сразу после того, как мы загрузим изображение. Для этого объединим все действия выше в один метод и скажем, чтобы его выполняла загрузочная кнопка: . def on_click(change): img = PILImage.create(btn_upload.data[-1]) placeholder.clear_output() with placeholder: display(img.to_thumb(250,250)) pred, ndx, probs = learner_s.predict(img) lbl_pred.value = f&#39;Предсказание: {pred}; Вероятность: {probs[ndx]:.04f}&#39; btn_upload.observe(on_click) . Теперь давайте соберем все элементы вместе. Расположим их друг над другом в элементе VBox: . VBox([widgets.Label(&#39;Загрузите картинку с кошкой или собакой!&#39;), btn_upload, placeholder, lbl_pred]) . Voil&#224; . Здорово, правда? Но это не все. Все-таки, приложение в блокноте не всегда нас полностью удовлетворяет. Нам не хочется показывать другим людям блокнот с кодом, нам хочется показать только конечный разультат. И тут нам на помощь приходит Voilà. Voilà - система, которую можно использовать как отдельное приложение, а можно как расширение jupyter notebook-а, что мы и будем делать. Voilà создает веб приложение из jupyter notebook-а: он отображает выводы из ячеек, текстовые ячейки и IPython widgets и при этом скрывает ячейки с кодом. . Давайте вынесем в отдельный блокнот только тот код, который нам необходим для создания веб-приложения (то есть загрузку модели и создание приложения с помощью виджетов). Можете добавить какой-нибудь текст, оформленный с помощью Markdown. . Чтобы установить voila, скопируйте следующую ячейку в блокнот и раскомментируйте строки. Первая строка устанавливает Voilà, а вторая устанавливает связь между нею и блокнотом. Или можно использовать командную строку. . # !pip install voila # !jupyter serverextension enable voila --sys-prefix . После установки, если она прошла успешно, у вас должен появиться значок Voilà. Примерно вот такой: . Можно нажать на него и увидеть результат. А можно в URL вашего текущего блокнота заменить &quot;notebook&quot; на &quot;voila/render&quot;, результат будет тот же. . Помните, в моем посте о приборах и материалах я говорила, что в Colab-е возникают проблемы с использованием voila? Если вы работаете на Colabe и у вас возникли проблемы, попробуйте проделать тоже самое, например, в Gradient-е или даже у себя на локальном компьютере, ведь модель уже обучена, и мы можем обойтись и без мощного ГПУ. Только не забудьте подгрузить файл с вашей моделью. . Binder . Все это, конечно, хорошо, но хочется, чтобы мы могли показывать свои достижения не только со своего компьютера. Именно для удовлетворения этой потребности и существует Binder. Binder - ПО, которое из Git-репозитория делает веб-приложение. . Как это работает? . Создаем репозиторий в своем GitHub-аккаунте,куда загружаем: . jupyter notebook, в котором и содержится наше приложение | обученную модель | файл requirements.txt, в котором указаны требования к библиотекам и зависимостям, необходимым для работы нашего приложения. В нашем конкретном случае в файле содержатся 5 строк: . voila fastai&gt;=2 pillow&lt;7 packaging ipywidgets==7.5.1 . | . | На сайте https://mybinder.org/ указываем ссылку на репозиторий в строке &quot;GitHub repository name or URL&quot;, в строке &quot;URL to open&quot; вводим /voila/render/имя_вашего_jupyter_notebookа.ipynb и заменяем File на URL в выпадающем списке, как показано на картинке. | Нажимаем кнопку launch. | Binder находит файл с зависимостями (requirements.txt) и, опираясь на него, начинает строить Docker образ нашего репозитория. Если для этого репозитория уже был построен образ, то он не будет перестраивать его заново. Если были произведены какие-то изменения в репозитории, то образ тоже обновится. | Когда образ построен, запустится страничка с вашим приложением. Вы можете использовать ссылку на него, чтобы поделиться своими успехами с друзьями. | Ура! Приложение готово, и нам не пришлось долго мучиться с его оформлением и размещением! Если у вас возникли проблемы, можете посмотреть для примера на мой репозиторий https://github.com/IrinaProkofieva/BearClassifier. Если у вас возникли вопросы, пишите в комментариях) . До новых встреч! .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/10/01/Want-to-share.html",
            "relUrl": "/fastpages/jupyter/2020/10/01/Want-to-share.html",
            "date": " • Oct 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Приборы и материалы",
            "content": "Прежде чем перейти к практике, обсудим, что нам понадобится для работы. . &#1063;&#1090;&#1086;, &#1075;&#1076;&#1077;, &#1086;&#1090;&#1082;&#1091;&#1076;&#1072;? . Первый вопрос, который может возникнуть - на чем писать? На данный момент самым популярным языком в сфере машинного обучения и нейросетей в частности является Python. У Python-а много достоинств, среди которых довольно простой синтаксис и большое количество всевозможных библиотек и пакетов. Он используется во многих крупных компаниях (Google, Intel, Microsoft и многие другие), а еще частично на нем написаны YouTube, Instagram, Facebook и др. . Определили язык, теперь встает второй вопрос - где писать? Для python существуют различные IDE, например PyCharm или Spyder, но для задач машинного обучения, по моему наблюдению, обычно используется Jupyter Notebook. Jupyter Notebook - часть проекта Jupyter. . Jupyter Project - некоммерческий проект с открытым исходным кодом, выросший из более раннего проекта IPython Project в 2014 году и созданный для поддержки разработок в области data science (науки о данных). Jupyter предоставляет разные штуки, но главное, что нас интересует, это Jupyter Notebook. Jupyter Notebook - веб-приложение с открытым исходным кодом, которое позволяет создавать и делиться документами, содержащими код, изображения, графики и просто текст на естественном языке. А так же делает возможной и комфортной работу с данными, числовыми моделями, статистическими моделями, визуализацией данных, машинным обучением и прочее, и прочее. Так что это очень классная среда разработки, предоставляющая для машинного обучения удобные инструменты. Работа ведется в режиме REPL, что может казаться не очень привычным, но в реальности очень удобным. Кстати, этот пост тоже написан в jupyter notebook-е) . . Между прочим, чтобы если у вас уже установлена Anaconda, то Jupyter Notebook у вас уже есть. В двух словах про Anaconda: . Anaconda — это дистрибутивы Python и R. Он предоставляет все необходимое для решения задач по анализу и обработке данных (с применимостью к Python). . (Определение взято отсюда) Так что вместо отдельной установки Jupyter Notebook и кучи разных библиотек можно просто поставить Anaconda. Кажется, довольно удобно. . . Jupyter Notebook установили, готовы обучать нейросеть. Но вот проблема: для обучения нам нужно мощное ГПУ, а где ж его взять? Да и с настройками возиться неохота. Вот и третий вопрос - откуда взять ГПУ? . Здесь есть несколько вариантов. Расскажу про два: Colaboratory(Colab) и Paperspace Gradient. . Google Colab - сервис, позволяющий работать с jupyter notebook-ами и предоставляющий бесплатный доступ к мощному GPU на 12 часов. . За что мне нравится Colab:1. Возможность загружать jupyter notebook-и с диска, с локального компьютера, с GitHub-а и создавать новые.2. Единственное, что нужно для того, чтобы начать работу с Colab-ом - Google аккаунт. И никакой предварительной регистрации, никаких долгих настроек. . Удобный доступ к данным на Google-диске. | Независим от платформы: не важно, какая ОС стоит на вашем ноутбуке. | Интуитивно понятный интерфейс. | Какие минусы у Colab-а я заметила: . Горячие клавиши немного отличаются от тех, которые в Jupyter-е. Это не проблема, в большинстве случаев надо просто добавить еще Ctrl+M, но сначала может быть непривычно. | При попытке использования voila (о том, что это такое, будет в одной из следующих статей) у меня возникли проблемы, которые я так и не смогла решить. Кажется, Google Colab не поддерживает voila :( (но я могу ошибаться!) | Несмотря на небольшие недостатки, я предпочитаю пользоваться именно этой платформой. . . Paperspace Gradient - платформа, которая предоставляет как платные, так и бесплатные GPU и CPU для машинного обучения. . Как и Colab, Gradient работает с jupyter notebook-ами. Бесплатный сервер предоставляется только на 6 часов, затем надо будет переподключаться. Возможна ситуация, когда все бесплатные машины заняты, и в таком случае придется немного подождать. . Вообще, у меня Gradient очень сильно тормозил, когда я работала на нем, поэтому я предпочитаю Colab. Но у Gradient тоже есть свои преимущества, например: . Один раз установив все библиотеки в проекте, вам больше не придется их переустанавливать. | Платные варианты машин в Gradient-е гарантируют, что обучение вашей модели не прервется за шаг до окончания, в то время как в Colabe сервер предоставляется всегда только на 12 часов. | . &#1040; &#1095;&#1090;&#1086; &#1077;&#1097;&#1077;? . А в общем-то все. Можно приступать к обучению! Но я хочу еще рассказать вот о чем: Существуют разные библиотеки для глубокого обучения, одна из самых популярных сейчас - это, наверное, PyTorch. Я уже говорила, что прохожу сейчас курс Practical Deep Learning for Coders от создателей библиотеки fastai, поэтому в моих постах часто будут встречаться примеры с использованием этой библиотеки. . fastai - библиотека, упрощающая жизнь разработчикам в области глубокого обучения. Она предоставляет многие базовые методы и классы, позволяющие значительно сократить объем кода; многие вещи уже заточены под выполнение на GPU; удобная и продуманная визуализация результатов и многое другое, что делает разработку приятнее и проще на всех уровнях разработки. . . На самом деле, fast.ai - это не только библиотека. Это сообщество, развивающее область глубокого обучения. Они не только разрабатывают свои библиотеки, но и ведут курсы, пишут книги, проводят научные исследования и публикуют разные интересные материалы. В общем, классные ребята, увлеченные своим делом. . Ну а вот теперь точно всё. Это была статья, в которой я рассказала о приборах и материалах, которые вам понадобятся, если вы решили познакомиться с машинным обучением поближе. Вопросы и замечания приветствуются! До новых встреч! . Фото автора cottonbro: Pexels .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/09/18/software.html",
            "relUrl": "/fastpages/jupyter/2020/09/18/software.html",
            "date": " • Sep 18, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Предвзятые нейросети",
            "content": "&#1057;&#1083;&#1099;&#1096;&#1072;&#1083;&#1080; &#1083;&#1080; &#1074;&#1099; &#1088;&#1072;&#1085;&#1100;&#1096;&#1077; &#1086; predictive policing? . Predictive policing - это система, которая призвана помочь полиции, основываясь на данных об уже совершенных преступлениях. Нейросети, которые, конечно же, там используются, получают на вход архивные данные и дают советы: например, куда и когда следует отправить полицейский патруль. Этот метод предотвращения преступлений, конечно, не является чудо-техникой, которая скажет: &quot;Я проанализировал материальное состояние жителей этого района и сделал вывод, что через час, вероятно, студент Раскольников убьет старуху-процентщицу и ее сестру. Отправьте туда пару полицейских.&quot; Конечно, нет. Эта система больше похожа на опытного полицейского-старожила, который сказал бы: &quot;У нас тут каждые полгода грабят продуктовый магазин за углом, наверное, в этот раз стоит послать туда пару ребят подежурить&quot;. Такой помощник появился в 2011 и сейчас используется в некоторых штатах США и в Китае. . . Казалось бы, что в этом может быть плохого? Но в начале этого года AI Now Institute провели исследование, которое показало обратную сторону медали. Дело в том, что данные, на которых обучалась данная модель, не были чистыми изначально. За долгую историю американской полиции было накопилось много дел, в которых большую роль сыграло расовое неравенство, и оказалось, среди прочего, что среди задержанных процент чернокожего населения был больше, чем процент белого. Основываясь на предоставленных ей данных, программа советовала отправить большую часть патрульных в районы, которые казались ей неблагополучными, например, афроамериканское гетто. Понятно, что без дела полиция не остаётся, и процент негров среди арестованных растет. Машина получает последние данные и видит, что большую часть преступников задержали в тех районах и советует послать туда ещё больше полицейских. Получается замкнутый круг и как следствие усугубление проблемы расового неравенства. Коррупция, выбивание показаний, предвзятость и многое другое, что находит отражение в данных для обучения, будут лишь множиться, если слепо следовать советам системы прогнозирования. . Такой замкнутый круг, когда результат одной итерации подается на вход другой, называется feedback loop, т.е. цикл с обратной связью. . Давайте подумаем, где ещё можно встретить такой цикл? На самом деле везде, где рекомендации машины предполагают совершение какого-то действия, где машина постоянно дообучается на новых данных, полученных в результате своей работы, и где изначальные данные не слишком чистые. . Мне в голову пришло ещё несколько примеров. . &#1055;&#1088;&#1080;&#1084;&#1077;&#1088; 1 . Где-то я читала о вспомогательной системе для отдела кадров, которая определяет по каким-то данным, насколько хорошо сотрудник вольётся в компанию. Так вот, можно предположить, что если в компании, например, мужчин работает больше, чем женщин, то выбирая между мужчиной и женщиной с одинаковыми навыками, программа отдаст предпочтение мужчине. Как вы понимаете, со временем коэффициент &quot;привлекательности&quot; для компании у мужчин сильно вырастет и программа станет ещё более предвзятой. На лицо feedback loop. Интересно, что похожая ситуация действительно имело место. Подробнее можно почитать здесь. . Изображение Coffee Bean с сайта Pixabay . &#1055;&#1088;&#1080;&#1084;&#1077;&#1088; 2 . Другой пример: представим, что мы обучаем своего чат-бота на открытых данных так, что он учится на реальных диалогах из интернета, а мы информацию для него практически не фильтруем. Внедряем наш чат-бот в среду, для которой он был предназначен, ну, скажем, на сайт для покупки билетов на футбольные матчи. И вдруг обнаруживается, что в том огромном датасете, на котором обучался наш помощник, были пару грубых диалогов и наша модель выучила несколько грубых фраз. Проблема в том, что машина не знает, что это плохие фразы и что так говорить нельзя, поэтому она случайно нагрубила в ответ какому-то футбольному фанату, который хотел уточнить, сколько нынче стоят билеты на матч. Понятное дело, тот может даже не догадываться, что отвечает ему не человек, но в любом случае хамство терпеть он не собирается и отвечает нашему боту соответствующим образом. Теперь наш бот знает ещё больше нехороших слов. И если разработчик вовремя не вмешается, мы вскоре обнаружим, что наша модель ведёт себя все более хамски. Опять feedback loop. . Просто вспомнилась история с грубоватым чат-ботом банка Тинькофф по имени Олег . &#1055;&#1088;&#1080;&#1084;&#1077;&#1088; 3 . Последний пример, который пришел мне на ум, не так хорош, так как не так близок к реальности. Если представить, что на распределение денег между регионами будет влиять обученная модель, то, вероятно, количество выделенных из бюджета средств будет пропорционально численности населения, площади города и количеству каких-нибудь крупных текущих проектов. Получив хорошее финансирование, крупный город M решил начать капитальный ремонт всего исторического центра. Увидев, что в городе М много начавшихся строек и реконструкций, система в следующем квартале выделяет ему ещё больше денег, но бюджет не безграничен, поэтому часть финансов забирают из суммы, которую в прошлый раз получили мелкие города, где никаких крупных строек не идёт уже лет 50. Как можно догадаться, обрадовавшись ещё большему финансированию, крупный город решает построить себе ещё пару офисных небоскребов и медучреждений с новейшим оборудованием. Вот он, порочный круг. С каждым разом программа будет предназначать все большие суммы крупным городам в ущерб мелким. . Photo by Sharon McCutcheon on Unsplash . &#1047;&#1072;&#1082;&#1083;&#1102;&#1095;&#1077;&#1085;&#1080;&#1077; . Такие ситуации встречаются, и предотвратить их очень сложно, ведь кристально чистых, &quot;непредвзятых&quot; данных практически не бывает. Что же делать? Не доверять все управление полностью системе, должен быть человек, который бы постоянно контролировал предсказания машины. Помните, что это только предсказания, то есть советы, а не точные инструкции. Машина бездушна, она не читала стихи Маяковского и не понимает, что такое хорошо, а что такое плохо. Поэтому прежде, чем следовать совету искуственного интеллекта, включите свой естественный. А моя статья подошла к концу. Спасибо за внимание! Если у вас есть замечания, предложения или другие интересные примеры таких циклов, пишите в комментариях! . Изображение Altmann с сайта Pixabay .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/09/10/Bias-networks.html",
            "relUrl": "/fastpages/jupyter/2020/09/10/Bias-networks.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Первый пост",
            "content": "Мой первый пост будет очень коротким, этакая проба пера (и различных возможностей Markdown-а). Когда начинаешь вести блог, сталкиваешься с кучей проблем: . Во-первых, конечно, встает вопрос, есть ли что-то, что ты можешь рассказать окружающим, что еще не было сказано до тебя? Практически всё сейчас ищется в интернете за пару кликов. Да что там! Даже клики делать не надо, просто говоришь: “Ок, Гугл. Могут ли машины захватить мир?” И результат у тебя перед глазами. | Во-вторых, волей-неволей задумываешься, обладаю ли я достаточным количеством знаний в той или иной области, чтобы еще и делиться своими мыслями на эту тему с другими людьми. | К тому же, число различных блогов растет день ото дня. Есть ли что-то такое, что будет отличать мой блог от сотни других? И все такое прочее. | . Но я сформулировала для себя несколько правил, которые эти проблемы решают, и на которые я и буду опираться в дальнейшем: . Данный блог я веду в первую очередь для себя. Я веду его, чтобы фиксировать свои идеи, чтобы напомнить мне будущей, какую большую работу я проделала, чтобы еще раз рассказать о том, что я узнала и утрамбовать свои знания в голове (кажется, это называется, закрепить полученные навыки). | Едва ли этот блог будет читать кто-то кроме меня. А если на него кто-нибудь чудом и наткнется, буду рада. Но если этому кому-то что-то не понравится - я никого тут не задерживаю. Этот блог не носит никаких коммерческих целей, поэтому нет цели завоевать признание миллионов. | Этот блог я веду в процессе обучения на курсе по машинному обучению. Ведение блога было рекомендацией авторов этого курса, поэтому, вероятно, на английском языке будет огромное число похожих блогов, но, думаю, на русском языке их число сильно меньше. | Что ж, вступление есть, теперь можно приступать к делу. . .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/markdown/2020/09/02/first-post.html",
            "relUrl": "/markdown/2020/09/02/first-post.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Искусственный интеллект и все-все-все",
            "content": "Очень часто люди, не имеющие дела с искуственным интеллектом лично, думают, что &quot;искусственный интеллект&quot;, &quot;машинное обучение&quot; и &quot;глубокое обучение&quot; - взаимо заменяемые словосочетания. Однако, это не совсем так. . Давайте посмотрим, какое определение искусственному интеллекту дает толковый словарь по искусственному интеллекту: . Интеллект Искусственный - научное направление, в рамках которого ставятся и решаются задачи аппаратного или программного моделирования тех видов человеческой деятельности, которые традиционно считаются интеллектуальными. . То есть это самый общий термин из всех трех, он, как можно догадаться, включает в себя все остальные, и обозначает целую область знаний. . Стоит заметить, что в обиходе под искусственным интеллектом обычно понимается умение машины выполнять какие-то действия наравне с человеком (или даже лучше). Здесь лучше подойдет второе определение: . Интеллект Искусственный - свойство интеллектуальных систем выполнять функции (творческие), которые традиционно считаются прерогативой человека. . . С искусственным интеллектом все вроде бы понятно. Этот термин можно почти безошибочно применять ко всему, что нам кажется достаточно умным для машины :) Перейдем к машинному обучению. Что это такое? Вот определение, которое я для себя вывела. . Машинное обучение - огромный подраздел искусственного интеллекта, характерной чертой которого является то, что алгоритм поиска решения некоторой задачи строится не на том, что мы пишем определенную последовательность команд, выполнение которых приводит к ответу, а на том, что машина сама находит закономерности в предоставленных ей данных и на основании этих закономерностей делает предсказания, каким может быть ответ. . Чтобы запомнить, что машинное обучение - только подраздел искуственного интеллекта, упомяну несколько других таких же подразделов: . Интеллектуальная робототехника | Экспертные системы | Машинное творчество и т.д. | . Конечно, зачастую эти подразделы переплетаются между собой. Главное, что отличает машинное обучение от остальных подразделов - самостоятельное получение машиной новых знаний. . Теперь глубокое обучение (deep learning). Глубокое обучение - один из видов машинного обучения. Это такой способ извлечения и обработки данных, который базируется на многослойных нейронных сетях. . Как это работает? Если в двух словах, то каждый слой сети состоит из нескольких нейронов. Каждый нейрон получает на вход данные от нейронов предыдущего уровня, обрабатывает полученную информацию, и передает обработанные данные нейронам из следующего слоя. . Это очень коротко и непонятно, но подробнее напишу об этом позже. Пока достаточно запомнить, что помимо глубокого обучения, есть еще такие виды машинного обучения, как: . Классические методы обучения (с учителем/без учителя) | Ансамблевые методы (Стеккинг, Беггинг, Бустинг) | Обучение с подкреплением | . Различных методов очень много и классифицировать их можно по-разному. Основное, что отличает глубокое обучение от остальных методов, это то, что обучение происходит на нейронных сетях с несколькими слоями. . Искусственный интеллект уже стал частью нашей повседневной жизни. Далее привожу примеры успешного использования ИИ. . Компьютерное зрение: . Распознавание номеров автомобилей | Распознавание лиц | Беспилотные автомобили | Поиск фотографий на телефоне по таким запросам, как &quot;закат&quot;, &quot;пикник&quot;, &quot;Новый год&quot; и т.д. | . В медицине: . Диагностирование рака | Нахождение различных патологий на рентгеновских снимках, МРТ и др. | . Обработка естественного языка: . Распознавание речи (&quot;Привет, Алиса&quot;, &quot;Ок, Google&quot; и т.п.) | Классификация документов по темам | Поддержание разоговора, ответы на вопросы (различные чат-боты) | Генерация текста | . А так же: . Рекомендательные системы: Расположение ссылок в поисковиках по релевантности, подбор фильмов, &quot;Вам также может понравиться...&quot;, контекстная реклама и вот это всё. . Игры: Искуственный интеллект уже обыграл человека в шахматы и Го, а помимо этого умеет проходить много других игр. . На видео: программист из Австралии научил ИИ играть в динозаврика из Chrome. Видео длинное, но посмотреть любопытно. . И многое-многое другое... ИИ врывается во многие сферы жизни, и мы сами уже не замечаем, что встречаемся с ним ежедневно. . &#1050;&#1072;&#1082; &#1088;&#1072;&#1073;&#1086;&#1090;&#1072;&#1077;&#1090; &#1085;&#1077;&#1081;&#1088;&#1086;&#1085;&#1085;&#1072;&#1103; &#1089;&#1077;&#1090;&#1100;? . Представим ситуацию: нам нужно отправить большой архив фотографий бабушке, но при этом не хотим, чтобы она увидела, что кто-то из её любимых внуков завел дома удава. Руками перебирать все фотографии очень долго, поэтому мы хотим написать такую программу, которая сама могла бы определить, есть ли на фото удав или нет. Время выхода нейронной сети на сцену! . Мы хотим, чтобы общая концепция была такая: скармливаем фото программе, она что-то с ней делает, а нам только выдает результат: &quot;Все отлично, удава здесь нет&quot;. . На самом деле, программе не достаточно получить только фотографию, она еще хочет получить параметры - набор значений для её внутренних переменных, чтобы она точно знала, что делать с входными данными - искать удава или искать закат. То, что мы получим на выходе, напрямую зависит от этих самых параметров. . Откуда нам взять параметры? . С разными параметрами наша модель (модель - программа, поведение которой определяется параметрами) и предсказывает по-разному. Чтобы достичь максимума точности в таком непростом деле, как детектирование удава, было бы неплохо, если бы она сама умела сравнивать эффективность при разных параметрах и запоминать лучшие. А еще мы бы хотели, чтобы она сама умела подбирать параметры так, чтобы её точность повышалась. . Например, подаем мы ей на вход параметры (а1, а2, а3, ... ,аn) и набор фотографий с пометками о наличии на них удава. Модель берет фотографию и говорит: &quot;Здесь есть удав с вероятностью 60%&quot;. Потом смотрит в ответы и видит, что удав тут и на самом деле есть. Тогда она думает: &quot;Хм, параметр а10 сбил меня с мысли, а ведь параметры а11 и а25 мне говорили, что тут точно есть удав&quot;. Берет следующую фотографию. Точно так же делает предположение, сверяет с ответом, смотрит, какие параметры надо поменять. Когда она проделает это со всеми поданными на вход фотографиями, она определяет точность, с которой она сейчас умеет определять удава. Например, она находит удава на фото в 75% случаев. Теперь она предлагает поменять определенные параметры, например, а10 уменьшить, а а11 и а25 увеличить.Теперь с этими параметрами она снова берет все фотографии и проделывает все то же самое. И оп! С такими параметрами она находит удава в 83% случаев. Опять корректирует значения и так далее. Прелесть в том, что модель делает все это без нашей помощи и учится на своих ошибках. . При этом модели важно не просто то, что она сказала, что &quot;здесь есть удав&quot;, но и еще и то, с каким качеством она это сделала, насколько она уверена в своих результатах. И её цель - повысить именно это качество, стать увереннее в себе :), а не просто выдать какой-то ответ. . Когда нам нравится качество, с которым модель предсказывает результаты, мы сохраняем параметры, при которых оно достигается. Теперь наша модель уже обучена. В следующий раз нам не придется заново учить её опознавать удавов - мы загружаем ей свои фотографии (уже без ответов), а она, пользуясь параметрами, полученными в прошлый раз, сразу выдает результат. . . Внесем ясность: . Получается, обучение модели (fit, train) - подбор параметров таким образом, чтобы на помеченных данных точность предсказаний была максимальной. . Заметим, что модель состоит из некоторой функции (архитектуры) и параметров. . В качестве архитектуры модели тут как раз будут использоваться нейронные сети. . В качестве метода улучшения параметров - функции оптимизации - часто выступает SGD (стохастический градиентный спуск). . Результаты, которые выдает модель, называются предсказаниями (predictions). . Полное прохождение всех входных данных одного цикла называется эпохой (epoch). . Функция, с помощью которой измеряется качество, называется функцией потерь (loss). Функция потерь выбирается так, чтобы её понимала сама модель и на её основании делала вывод, какие параметры как поменять. Если же мы уже обучили нейросеть и хотим похвастаться другу, как она хороша, или если мы хотим более точно понимать, насколько хороша модель в конце каждой эпохи и какое качество она показывает на валидационной выборке (что это такое будет ниже), мы используем метрики. Метрика - понятная для человека функция, показывающая эффективность модели. . А правильные ответы, которые мы загружаем вместе с фотографиями при обучении модели и которые пытается отгадать модель, по-английски называются labels или targets, а в русском языке я их названий точно не знаю, может, таргеты или лейблы :) . . Итак, повторим еще раз: . В архитектуру загружаются входные данные (например, фотографии) и параметры. Архитектура делает предсказания. Затем они сверяются с таргетами и функция потерь выдает качество модели. С помощью функции оптимизации улучшаем параметры и снова загружаем их в архитектуру вместе в входными данными. Следующая эпоха. . Примечание: Думаю, очевидно, что после обучения модель сможет распознавать только такие шаблоны, которые встречала во входных данных. Если она училась только на фотографиях кошек, то она не сможет распознать кошку, нарисованную от руки. . Представим ситуацию: мы выдали модели большое число помеченных фотографий с удавами и без, обучение проходит идеально: точность 100%. Сохраняем эти параметры и на радостях загружаем фотографию, где мы обнимаемся с удавом. И вдруг результат: на этой фотографии удава нет. Как же так? Ведь модель обещала нам стопроцентную точность! Скорее всего, дело в том, что модель во время обучения просто запомнила все наши картинки и их таргеты, поэтому и выдавала к ним все время верные ответы, а саму суть (то, как выглядит удав) так и не поняла. Говорят, что модель ПЕРЕобучилась (overfitting). Чтобы этого избежать, обычно перед обучением входные помеченные данные делят на две группы - обучающая выборка (trainig set) и проверочная выборка (validation set). Обычно для проверки используют 20-30% всех данных. Процесс обучения проходит только на обучающей выборке, а эффективность модели в конце каждой эпохи оценивается на проверочной, потому что эти данные модель раньше точно не видела и точно не могла их выучить. Причем каждый раз эта валидационная выборка, однажды выбранная, должна оставаться одной и той же. В большинстве случаев данные, входящие в эту выборку выбираются из общего числа данных случайным образом, но в некоторых случаях оценка точности на случайной выборке не является адекватным критерием эффективности. Например, мы хотим каким-то образом научить модель предсказывать ближайший рост или падение акций компании N на основе имеющейся у нас истории поведения стоимости её акций за прошлые 10 лет. Если мы в валидационную выборку включим случайные даты из последних 10 лет, то модель может догадаться, сколько стоили акции на основе предыдущего и последующего дней. Однако в реальности у нас нет этого &quot;последующего&quot; дня: мы хотим угадать стоимость акций завтра, но не знаем, сколько они будут стоить послезавтра. Поэтому для проверки реальной эффективности, логичнее в валидиционную выборку включить, например, последние 2 месяца из имеющейся у нас истории и посмотреть, насколько предсказания модели соответствуют действительности. То есть если наши предсказания будут каким-то образом упорядочены по оси времени, то к формированию проверочной выборки надо относиться аккуратнее! . Примечание: Несмотря на то, что мы заблаговременно разделили наши данные на обучающие и проверочные, мы все равно можем столкнуться с проблемой запоминания данных. Но так мы хотя бы сможем установить этот факт уже в процессе обучения, а не после: точность на обучающей выборке будет расти, в то время как точность на валидационной выборке будет ухудшаться. . Обычно присутствует еще тестовая выборка (test set), для самой финальной проверки. Её модель не видит ни разу за время обучения, и ею проверяют точность на самой последней стадии работы. Например, на соревнованиях эту выборку не видят участники, она доступна только для проверки сданных работ(моделей). Или если вам делают модель на заказ, то часть размеченных данных заказчик может оставить себе, не показывая разработчику, и уже при приемке готовой работы проверить точность модели на этих данных. . Конечно, модель можно полностью написать самому. Но если вы не тот самый человек, который готов потратить огромное количество времени на написание собственной модели, не будучи уверенным, что она даст сильный выигрыш по времени, то будет гораздо удобнее взять уже готовые модели и дообучать их на своем конкретном случае. Такие модели называются предобученными, так как они уже обучились на каких-то больших наборах данных (dataset). Таких готовых моделей существует очень много. Например, для классификации изображений существуют такие готовые модели, как ResNet или VGG. Они обучены уже на огромном датасете ImageNet и уже умеют находить на изображении множество разных шаблонов. . ImageNet - один из самых известных бесплатных больших дасатетов. Он насчитывает наборы изображений для более, чем 100000 классов. Для каждого класса предоставляется в среднем 1000 картинок. Пометки о том, к какому классу относится изображение, сделаны людьми, и качество данных контролируется. . Для задач компьютерного зрения используются сверточные нейронные сети, сокращенно - CNN (Convolutional neural network). Как несложно догадаться, они используют операцию свертки. О том, как именно они работают будет в одной из следующих статей. . При работе с изображениями перед обучением данные обычно обрабатывают различными способами, чтобы получить еще больше данных. Например, увеличивают яркость, вращают, растягивают, добавляют шум и т.д. Английский термин для этого - data augmentation. Но в любом случае перед загрузкой в модель все файлы приводят к одинаковому размеру. Обычно можно увидеть приведение к размеру 224x224, но число 224 не несет в себе особой смысловой нагрузки. Так сложилось исторически и не более чем формальность - вы можете выбрать другой размер. Чем больше размер - тем лучших результатов можно достичь, правда, ценой будет более долгий процесс обучения и бОльшие требуемые мощности. . На сегодня, пожалуй, хватит. В этой статье я ввела множество основных терминов, но не углублялась в теорию. Если у вас есть вопросы или замечания, пишите в комментариях, а я пошла готовить следующую статью. До новых встреч! . Photo by Jan Tinneberg on Unsplash .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/09/02/IA-and-everything.html",
            "relUrl": "/fastpages/jupyter/2020/09/02/IA-and-everything.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://irinaprokofieva.github.io/my-ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://irinaprokofieva.github.io/my-ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}