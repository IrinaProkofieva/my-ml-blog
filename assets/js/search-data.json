{
  
    
        "post0": {
            "title": "Хочу делиться",
            "content": "После того, как ты обучил модель, которая показывает хорошие результаты, всегда хочется поделиться этой радостью с окружающими, хочется сказать: &quot;Смотри, у меня есть модель, которая может сказать, кто на картинке: кошка или собака. Хочешь попробовать? Вот загрузи фотографию своей Мурки&quot;. Но делать клиент-серверное приложение с крутым дизайном очень лень, на это ты потратишь больше времени, чем на саму модель. Что же делать? Не отправлять же всем свой код, в самом деле! Выход есть! Нам поможет... Подождите, давайте все сделаем попорядку. . &#1054;&#1073;&#1091;&#1095;&#1072;&#1077;&#1084; &#1084;&#1086;&#1076;&#1077;&#1083;&#1100; . В этой статье у меня нет цели рассказать вам в подробностях, как обучать модель, цель этой статьи - показать, как быстро получить из модели готовое приложение. Поэтому на этом разделе не буду долго задерживаться. Итак, обучение модели. Поехали! . Сначала импортируем библиотеку. Раскомментируйте первую ячейку, если у вас еще не установлен fastai или установлена старая версия. . #!pip uninstall fastai #!pip install fastai . from fastai.vision.all import * from fastai.vision.widgets import * . Теперь возьмем уже существующий датасет с кошками и собаками, который нам предоставляет эта библиотека, и загрузим его на свою машину: . path = untar_data(URLs.PETS) path . Path(&#39;/root/.fastai/data/oxford-iiit-pet&#39;) . Метод untar_data, как я уже сказала, скачивает датасет на сервер, где производятся вычисления: если вы считаете на локальном компьютере, то скачивает на ваш локальный компьютер, если вы считаете где-нибудь на Colab или Gradient, то на ту виртуальную машину и загружает. Затем этот метод распаковывает архив, если данные заархивированы, и возвращает путь, где лежат конечные данные. Давайте посмотрим, что лежит внутри загруженной папки: . Path.BASE_PATH = path path.ls() . (#2) [Path(&#39;annotations&#39;),Path(&#39;images&#39;)] . Вы видели, какой у нас длинный путь, в котором лежит датасет. Чтобы не отображать его каждый раз, в первой строчке мы сделали адрес этой папки базовым. Таким образом, когда мы с помощью метода ls() отображаем содержимое папки, мы видим пути относительно этого базового адреса. Итак, у нас внутри две папки: annotations и images. Папка annotations нас не интересует - там лежат данные для определения конкретного места на картинке, где изображены животные. Нас интересует папка images. Давайте заглянем в нее: . path = path/&#39;images&#39; path.ls() . (#7393) [Path(&#39;images/samoyed_21.jpg&#39;),Path(&#39;images/newfoundland_48.jpg&#39;),Path(&#39;images/wheaten_terrier_139.jpg&#39;),Path(&#39;images/leonberger_1.jpg&#39;),Path(&#39;images/samoyed_175.jpg&#39;),Path(&#39;images/miniature_pinscher_110.jpg&#39;),Path(&#39;images/german_shorthaired_3.jpg&#39;),Path(&#39;images/wheaten_terrier_131.jpg&#39;),Path(&#39;images/pomeranian_123.jpg&#39;),Path(&#39;images/Egyptian_Mau_77.jpg&#39;)...] . Все верно. В папке images лежат 7393 изображения с кошками и собаками различных пород. Если мы внимательно посмотрим на названия картинок, то увидим, что это названия пород. А если посмотрим еще более внимательно, то увидим, что породы кошек написаны с большой буквы, а собак - с маленькой. Ну или можно было получить эту информацию с сайта, с которого мы скачали наши данные:) Породы нам пока не нужны, а вот принцип отделения кошек от собак полезен. Оформим его в виде отдельного метода: . def cat_or_dog(x): return &#39;Cat&#39; if x[0].isupper() else &#39;Dog&#39; . Загрузим наши данные таким образом, чтобы они представляли собой структуру, удобную для дальнейшей обработки. В этом нам поможет класс ImageDataLoaders: . dls = ImageDataLoaders.from_name_func(path, get_image_files(path), valid_pct = 0.2, seed = 42, label_func = cat_or_dog, item_tfms = Resize(224)) . Если вы читали мой пост, в котором я рассказывала об основных понятиях нейронных сетей, то вы быстро поймете, что здесь произошло, а если нет, то предлагаю вам быстренько с ним ознакомиться. Итак, разбираем построчно. dls - переменная, в которой будет храниться структура из наших изображений. ImageDataLoaders - собственно класс, который эту структуру представляет. Эта структура удобна тем, что в ней хранится информация, откуда брать таргеты (labels) для изображений, откуда брать сами изображения, как их делить на тренировочные и валидационные выборки и многое другое. Собственно, функция from_name_func и показывает, что при создании загрузчика файлов(этой самой структуры), таргеты для каждого изображения будем брать из его имени. Функции передаем: . путь, откуда брать файлы; | функцию, показывающую, каким образом брать эти файлы (get_image_files - брать изображения рекурсивно из каждой подпапки); | valid_pct - какую часть от всех изображений выделить под валидационную выборку; | seed - ядро для рандома, чтобы в валидацонную выборку попали случайные изображения, но чтобы на каждой эпохе эта выборка была одной и той же; | label_func - задаем функцию, каким образом получить таргет. Помните, мы определили метод, определяющей по первой букве названия файла кошка перед нами или собака? Его мы и передадим. | item_tfms - какие преобразования проделать с каждым изображением. В данном случае просто преобразуем все изображения к одному размеру (224*224), чтобы можно было работать с ними на ГПУ. | . Как видите, ничего сложного. Делаем все необходимое, что написано в том посте, который я только что упомянула, буквально в одной строчке. Идем дальше. Данные готовы, что делаем с моделью? Возьмем предобученную модель и дообучаем ее на своих данных. Для нашей не самой сложной модели возьмем хорошую сеть из 34-ти слоев: ResNet34. . learner = cnn_learner(dls, resnet34, metrics=error_rate) . Метод cnn_learner строит сверточную нейронную сеть из наших данных и из предобученной модели. Мы можем передать ему большое число параметров, например, loss function, оптимизирующую функцию, шаг (learning rate) и так далее. Но сейчас мы передали ему только метрику, которую хотели бы использовать - error_rate (отношение количества ошибочных предсказаний к общему числу предсказаний). Кстати, если вы хотите подробнее узнать о той или иной функции, то можете использовать метод doc() или поставить ? или ?? перед именем функции. Попробуйте, это удобно! . doc(cnn_learner) . cnn_learner(dls, arch, loss_func=None, pretrained=True, cut=None, splitter=None, y_range=None, config=None, n_out=None, normalize=True, opt_func=&lt;function Adam at 0x7f27e8840378&gt;, lr=0.001, cbs=None, metrics=None, path=None, model_dir=&#39;models&#39;, wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95)) Build a convnet style learner from `dls` and `arch` To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev . ?cnn_learner . ??cnn_learner . Итак, нам остался последний шаг - собственно, само обучение. Вернее, дообучение модели на наших данных: . learner.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 0.122511 | 0.023786 | 0.005413 | 00:50 | . epoch train_loss valid_loss error_rate time . 0 | 0.060866 | 0.060334 | 0.014208 | 00:54 | . 1 | 0.040196 | 0.015185 | 0.004060 | 00:54 | . 2 | 0.018751 | 0.006086 | 0.002706 | 00:54 | . 3 | 0.009726 | 0.012300 | 0.002706 | 00:55 | . Дообучение модели иногда называют файнтьюнингом от английского термина fine-tune. Поэтому метод дообучения так и называется. В качестве параметра мы передаем число эпох. Например, 4. . 4 эпохи дали нам очень неплохой результат. Я удовольствуюсь им, а вы, если хотите, можете посмотреть, как будет изменяться точность с дальнейшим обучением. . Можем сохранить нашу модель, чтобы в следующий раз, когда она нам понадобится, нам не пришлось заново ее обучать. Есть 2 способа сохранить модель: . Можно сохранить только параметры, тогда при следующем использовании мы будем брать брать нужную нам архитектуру модели (в данном случае, resnet34) и передавать ей сохраненные параметры. | Можно сохранить сразу все: и параметры, и архитектуру, и при следующем использовании нам просто надо будет просто взять модель из сохраненного файла. | Как вы догадываетесь, в первом случае сохраненный файл весит гораздо меньше, но требуется чуть больше хлопот. Не будем пока заморачиваться и сохраним всю модель целиком, как в пункте 2: . learner.export(os.path.abspath(&#39;./export.pkl&#39;)) . Метод export сохраняет модель в файл с разрешением .pkl в текущую папку. По умолчанию имя файла будет &quot;export.pkl&quot;, но вы можете передать в метод другое имя или абсолютный путь. Проверим, что все сохранилось: . path = Path() path.ls(file_exts=&quot;.pkl&quot;) . (#1) [Path(&#39;export.pkl&#39;)] . Но если в Gradient ваша модель сохранится за вами, и вы снова увидите ее, если зайдете на следующий день, то с Colab-ом так, к сожалению, не прокатит. Зато с Colab удобно сохранять модель на гугл-диск. Для этого надо зайти на свой диск и выбрать место, куда сохранить: . from google.colab import drive drive.mount(&#39;/content/gdrive&#39;) . Mounted at /content/gdrive . learner.export(&#39;/content/gdrive/My Drive/export.pkl&#39;) . Можете проверить, на вашем Google диске должен появиться файл с расширением .pkl. . &#1048;&#1089;&#1087;&#1086;&#1083;&#1100;&#1079;&#1091;&#1077;&#1084; &#1075;&#1086;&#1090;&#1086;&#1074;&#1091;&#1102; &#1084;&#1086;&#1076;&#1077;&#1083;&#1100; . Теперь мы хотим загрузить полученную нами модель для дальнейшего использования. (Конечно, загружать модель в этом же блокноте нам сейчас особого смысла нет, но давайте представим, что мы создали новый jupyter-notebook и теперь работаем в нем. Кстати, вы можете именно так и поступить!) Чтобы загрузить модель, используем метод load_learner. . learner_s = load_learner(path/&#39;export.pkl&#39;) . Модель загружена. Давайте посмотрим, помнит ли она, на какие два класса она должна делить изображения. Обратимся к загрузчику классов и посмотрим, какие таргеты у него есть: . learner_s.dls.vocab . (#2) [&#39;Cat&#39;,&#39;Dog&#39;] . Отлично. Чтобы сделать предсказание, будем пользоваться методом predict. Но для начала давайте получим самый простой интерфейс для загрузки картинок и &quot;скармливания&quot; их нашей модели. Начинается самая интересная часть, ради которой и была написана эта статья. . IPython widgets . Для людей, не сильно любящих заниматься разработкой графического пользовательского интерфейса(GUI), существуют IPython widgets. Это GUI-компоненты, помогающие быстро и без особых трудностей создать простой пользовательский интерфейс прямо в jupyter notebook-е. Давайте посмотрим, что он умеет. . Создадим кнопку для загрузки изображения с локального компьютера. Самое прекрасное, что такая кнопка уже есть в виджетах и нам не придется писать для нее функционал самим. . btn_upload = widgets.FileUpload() btn_upload . Попробуйте загрузить какое-нибудь изображение. Чтобы его отобразить, выделим место, в котором будут отображаться загруженные картинки: . placeholder = widgets.Output() placeholder . Видите, мы его создали, но пока там пусто. Давайте отобразим там ваше загруженное изображение: . img = PILImage.create(btn_upload.data[-1]) with placeholder: display(img.to_thumb(250,250)) . Чтобы снова очистить это место, используем метод clear_output(): . placeholder.clear_output() . А теперь посмотрим, что скажет нам наша модель: . learner_s.predict(img) . (&#39;Cat&#39;, tensor(0), tensor([1.0000e+00, 1.6606e-11])) . Здорово! Нам выводится 3 значения: . Таргет (класс, к которому наша модель относит наше изображение) | Порядковый номер этого класса | Вероятности, с каким это изображение относится к каждому из классов | Давайте создадим специальное место, где будем отображать предсказание: . pred, ndx, probs = learner_s.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Предсказание: {pred}; Вероятность: {probs[ndx]:.04f}&#39; lbl_pred . Хочется, чтобы картинка и предсказания отображались сразу после того, как мы загрузим изображение. Для этого объединим все действия выше в один метод и скажем, чтобы его выполняла загрузочная кнопка: . def on_click(change): img = PILImage.create(btn_upload.data[-1]) placeholder.clear_output() with placeholder: display(img.to_thumb(250,250)) pred, ndx, probs = learner_s.predict(img) lbl_pred.value = f&#39;Предсказание: {pred}; Вероятность: {probs[ndx]:.04f}&#39; btn_upload.observe(on_click) . Теперь давайте соберем все элементы вместе. Расположим их друг над другом в элементе VBox: . VBox([widgets.Label(&#39;Загрузите картинку с кошкой или собакой!&#39;), btn_upload, placeholder, lbl_pred]) . Voil&#224; . Здорово, правда? Но это не все. Все-таки, приложение в блокноте не всегда нас полностью удовлетворяет. Нам не хочется показывать другим людям блокнот с кодом, нам хочется показать только конечный разультат. И тут нам на помощь приходит Voilà. Voilà - система, которую можно использовать как отдельное приложение, а можно как расширение jupyter notebook-а, что мы и будем делать. Voilà создает веб приложение из jupyter notebook-а: он отображает выводы из ячеек, текстовые ячейки и IPython widgets и при этом скрывает ячейки с кодом. . Давайте вынесем в отдельный блокнот только тот код, который нам необходим для создания веб-приложения (то есть загрузку модели и создание приложения с помощью виджетов). Можете добавить какой-нибудь текст, оформленный с помощью Markdown. . Чтобы установить voila, скопируйте следующую ячейку в блокнот и раскомментируйте строки. Первая строка устанавливает Voilà, а вторая устанавливает связь между нею и блокнотом. Или можно использовать командную строку. . # !pip install voila # !jupyter serverextension enable voila --sys-prefix . После установки, если она прошла успешно, у вас должен появиться значок Voilà. Примерно вот такой: . Можно нажать на него и увидеть результат. А можно в URL вашего текущего блокнота заменить &quot;notebook&quot; на &quot;voila/render&quot;, результат будет тот же. . Помните, в моем посте о приборах и материалах я говорила, что в Colab-е возникают проблемы с использованием voila? Если вы работаете на Colabe и у вас возникли проблемы, попробуйте проделать тоже самое, например, в Gradient-е или даже у себя на локальном компьютере, ведь модель уже обучена, и мы можем обойтись и без мощного ГПУ. Только не забудьте подгрузить файл с вашей моделью. . Binder . Все это, конечно, хорошо, но хочется, чтобы мы могли показывать свои достижения не только со своего компьютера. Именно для удовлетворения этой потребности и существует Binder. Binder - ПО, которое из Git-репозитория делает веб-приложение. . Как это работает? . Создаем репозиторий в своем GitHub-аккаунте,куда загружаем: . jupyter notebook, в котором и содержится наше приложение | обученную модель | файл requirements.txt, в котором указаны требования к библиотекам и зависимостям, необходимым для работы нашего приложения. В нашем конкретном случае в файле содержатся 5 строк: . voila fastai&gt;=2 pillow&lt;7 packaging ipywidgets==7.5.1 . | . | На сайте https://mybinder.org/ указываем ссылку на репозиторий в строке &quot;GitHub repository name or URL&quot;, в строке &quot;URL to open&quot; вводим /voila/render/имя_вашего_jupyter_notebookа.ipynb и заменяем File на URL в выпадающем списке, как показано на картинке. | Нажимаем кнопку launch. | Binder находит файл с зависимостями (requirements.txt) и, опираясь на него, начинает строить Docker образ нашего репозитория. Если для этого репозитория уже был построен образ, то он не будет перестраивать его заново. Если были произведены какие-то изменения в репозитории, то образ тоже обновится. | Когда образ построен, запустится страничка с вашим приложением. Вы можете использовать ссылку на него, чтобы поделиться своими успехами с друзьями. | Ура! Приложение готово, и нам не пришлось долго мучиться с его оформлением и размещением! Если у вас возникли проблемы, можете посмотреть для примера на мой репозиторий https://github.com/IrinaProkofieva/BearClassifier. Если у вас возникли вопросы, пишите в комментариях) . До новых встреч! .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/10/01/Want-to-share.html",
            "relUrl": "/fastpages/jupyter/2020/10/01/Want-to-share.html",
            "date": " • Oct 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Приборы и материалы",
            "content": "Прежде чем перейти к практике, обсудим, что нам понадобится для работы. . &#1063;&#1090;&#1086;, &#1075;&#1076;&#1077;, &#1086;&#1090;&#1082;&#1091;&#1076;&#1072;? . Первый вопрос, который может возникнуть - на чем писать? На данный момент самым популярным языком в сфере машинного обучения и нейросетей в частности является Python. У Python-а много достоинств, среди которых довольно простой синтаксис и большое количество всевозможных библиотек и пакетов. Он используется во многих крупных компаниях (Google, Intel, Microsoft и многие другие), а еще частично на нем написаны YouTube, Instagram, Facebook и др. . Определили язык, теперь встает второй вопрос - где писать? Для python существуют различные IDE, например PyCharm или Spyder, но для задач машинного обучения, по моему наблюдению, обычно используется Jupyter Notebook. Jupyter Notebook - часть проекта Jupyter. . Jupyter Project - некоммерческий проект с открытым исходным кодом, выросший из более раннего проекта IPython Project в 2014 году и созданный для поддержки разработок в области data science (науки о данных). Jupyter предоставляет разные штуки, но главное, что нас интересует, это Jupyter Notebook. Jupyter Notebook - веб-приложение с открытым исходным кодом, которое позволяет создавать и делиться документами, содержащими код, изображения, графики и просто текст на естественном языке. А так же делает возможной и комфортной работу с данными, числовыми моделями, статистическими моделями, визуализацией данных, машинным обучением и прочее, и прочее. Так что это очень классная среда разработки, предоставляющая для машинного обучения удобные инструменты. Работа ведется в режиме REPL, что может казаться не очень привычным, но в реальности очень удобным. Кстати, этот пост тоже написан в jupyter notebook-е) . . Между прочим, чтобы если у вас уже установлена Anaconda, то Jupyter Notebook у вас уже есть. В двух словах про Anaconda: . Anaconda — это дистрибутивы Python и R. Он предоставляет все необходимое для решения задач по анализу и обработке данных (с применимостью к Python). . (Определение взято отсюда) Так что вместо отдельной установки Jupyter Notebook и кучи разных библиотек можно просто поставить Anaconda. Кажется, довольно удобно. . . Jupyter Notebook установили, готовы обучать нейросеть. Но вот проблема: для обучения нам нужно мощное ГПУ, а где ж его взять? Да и с настройками возиться неохота. Вот и третий вопрос - откуда взять ГПУ? . Здесь есть несколько вариантов. Расскажу про два: Colaboratory(Colab) и Paperspace Gradient. . Google Colab - сервис, позволяющий работать с jupyter notebook-ами и предоставляющий бесплатный доступ к мощному GPU на 12 часов. . За что мне нравится Colab:1. Возможность загружать jupyter notebook-и с диска, с локального компьютера, с GitHub-а и создавать новые.2. Единственное, что нужно для того, чтобы начать работу с Colab-ом - Google аккаунт. И никакой предварительной регистрации, никаких долгих настроек. . Удобный доступ к данным на Google-диске. | Независим от платформы: не важно, какая ОС стоит на вашем ноутбуке. | Интуитивно понятный интерфейс. | Какие минусы у Colab-а я заметила: . Горячие клавиши немного отличаются от тех, которые в Jupyter-е. Это не проблема, в большинстве случаев надо просто добавить еще Ctrl+M, но сначала может быть непривычно. | При попытке использования voila (о том, что это такое, будет в одной из следующих статей) у меня возникли проблемы, которые я так и не смогла решить. Кажется, Google Colab не поддерживает voila :( (но я могу ошибаться!) | Несмотря на небольшие недостатки, я предпочитаю пользоваться именно этой платформой. . . Paperspace Gradient - платформа, которая предоставляет как платные, так и бесплатные GPU и CPU для машинного обучения. . Как и Colab, Gradient работает с jupyter notebook-ами. Бесплатный сервер предоставляется только на 6 часов, затем надо будет переподключаться. Возможна ситуация, когда все бесплатные машины заняты, и в таком случае придется немного подождать. . Вообще, у меня Gradient очень сильно тормозил, когда я работала на нем, поэтому я предпочитаю Colab. Но у Gradient тоже есть свои преимущества, например: . Один раз установив все библиотеки в проекте, вам больше не придется их переустанавливать. | Платные варианты машин в Gradient-е гарантируют, что обучение вашей модели не прервется за шаг до окончания, в то время как в Colabe сервер предоставляется всегда только на 12 часов. | . &#1040; &#1095;&#1090;&#1086; &#1077;&#1097;&#1077;? . А в общем-то все. Можно приступать к обучению! Но я хочу еще рассказать вот о чем: Существуют разные библиотеки для глубокого обучения, одна из самых популярных сейчас - это, наверное, PyTorch. Я уже говорила, что прохожу сейчас курс Practical Deep Learning for Coders от создателей библиотеки fastai, поэтому в моих постах часто будут встречаться примеры с использованием этой библиотеки. . fastai - библиотека, упрощающая жизнь разработчикам в области глубокого обучения. Она предоставляет многие базовые методы и классы, позволяющие значительно сократить объем кода; многие вещи уже заточены под выполнение на GPU; удобная и продуманная визуализация результатов и многое другое, что делает разработку приятнее и проще на всех уровнях разработки. . . На самом деле, fast.ai - это не только библиотека. Это сообщество, развивающее область глубокого обучения. Они не только разрабатывают свои библиотеки, но и ведут курсы, пишут книги, проводят научные исследования и публикуют разные интересные материалы. В общем, классные ребята, увлеченные своим делом. . Ну а вот теперь точно всё. Это была статья, в которой я рассказала о приборах и материалах, которые вам понадобятся, если вы решили познакомиться с машинным обучением поближе. Вопросы и замечания приветствуются! До новых встреч! . Фото автора cottonbro: Pexels .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/09/18/software.html",
            "relUrl": "/fastpages/jupyter/2020/09/18/software.html",
            "date": " • Sep 18, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Предвзятые нейросети",
            "content": "&#1057;&#1083;&#1099;&#1096;&#1072;&#1083;&#1080; &#1083;&#1080; &#1074;&#1099; &#1088;&#1072;&#1085;&#1100;&#1096;&#1077; &#1086; predictive policing? . Predictive policing - это система, которая призвана помочь полиции, основываясь на данных об уже совершенных преступлениях. Нейросети, которые, конечно же, там используются, получают на вход архивные данные и дают советы: например, куда и когда следует отправить полицейский патруль. Этот метод предотвращения преступлений, конечно, не является чудо-техникой, которая скажет: &quot;Я проанализировал материальное состояние жителей этого района и сделал вывод, что через час, вероятно, студент Раскольников убьет старуху-процентщицу и ее сестру. Отправьте туда пару полицейских.&quot; Конечно, нет. Эта система больше похожа на опытного полицейского-старожила, который сказал бы: &quot;У нас тут каждые полгода грабят продуктовый магазин за углом, наверное, в этот раз стоит послать туда пару ребят подежурить&quot;. Такой помощник появился в 2011 и сейчас используется в некоторых штатах США и в Китае. . . Казалось бы, что в этом может быть плохого? Но в начале этого года AI Now Institute провели исследование, которое показало обратную сторону медали. Дело в том, что данные, на которых обучалась данная модель, не были чистыми изначально. За долгую историю американской полиции было накопилось много дел, в которых большую роль сыграло расовое неравенство, и оказалось, среди прочего, что среди задержанных процент чернокожего населения был больше, чем процент белого. Основываясь на предоставленных ей данных, программа советовала отправить большую часть патрульных в районы, которые казались ей неблагополучными, например, афроамериканское гетто. Понятно, что без дела полиция не остаётся, и процент негров среди арестованных растет. Машина получает последние данные и видит, что большую часть преступников задержали в тех районах и советует послать туда ещё больше полицейских. Получается замкнутый круг и как следствие усугубление проблемы расового неравенства. Коррупция, выбивание показаний, предвзятость и многое другое, что находит отражение в данных для обучения, будут лишь множиться, если слепо следовать советам системы прогнозирования. . Такой замкнутый круг, когда результат одной итерации подается на вход другой, называется feedback loop, т.е. цикл с обратной связью. . Давайте подумаем, где ещё можно встретить такой цикл? На самом деле везде, где рекомендации машины предполагают совершение какого-то действия, где машина постоянно дообучается на новых данных, полученных в результате своей работы, и где изначальные данные не слишком чистые. . Мне в голову пришло ещё несколько примеров. . &#1055;&#1088;&#1080;&#1084;&#1077;&#1088; 1 . Где-то я читала о вспомогательной системе для отдела кадров, которая определяет по каким-то данным, насколько хорошо сотрудник вольётся в компанию. Так вот, можно предположить, что если в компании, например, мужчин работает больше, чем женщин, то выбирая между мужчиной и женщиной с одинаковыми навыками, программа отдаст предпочтение мужчине. Как вы понимаете, со временем коэффициент &quot;привлекательности&quot; для компании у мужчин сильно вырастет и программа станет ещё более предвзятой. На лицо feedback loop. Интересно, что похожая ситуация действительно имело место. Подробнее можно почитать здесь. . Изображение Coffee Bean с сайта Pixabay . &#1055;&#1088;&#1080;&#1084;&#1077;&#1088; 2 . Другой пример: представим, что мы обучаем своего чат-бота на открытых данных так, что он учится на реальных диалогах из интернета, а мы информацию для него практически не фильтруем. Внедряем наш чат-бот в среду, для которой он был предназначен, ну, скажем, на сайт для покупки билетов на футбольные матчи. И вдруг обнаруживается, что в том огромном датасете, на котором обучался наш помощник, были пару грубых диалогов и наша модель выучила несколько грубых фраз. Проблема в том, что машина не знает, что это плохие фразы и что так говорить нельзя, поэтому она случайно нагрубила в ответ какому-то футбольному фанату, который хотел уточнить, сколько нынче стоят билеты на матч. Понятное дело, тот может даже не догадываться, что отвечает ему не человек, но в любом случае хамство терпеть он не собирается и отвечает нашему боту соответствующим образом. Теперь наш бот знает ещё больше нехороших слов. И если разработчик вовремя не вмешается, мы вскоре обнаружим, что наша модель ведёт себя все более хамски. Опять feedback loop. . Просто вспомнилась история с грубоватым чат-ботом банка Тинькофф по имени Олег . &#1055;&#1088;&#1080;&#1084;&#1077;&#1088; 3 . Последний пример, который пришел мне на ум, не так хорош, так как не так близок к реальности. Если представить, что на распределение денег между регионами будет влиять обученная модель, то, вероятно, количество выделенных из бюджета средств будет пропорционально численности населения, площади города и количеству каких-нибудь крупных текущих проектов. Получив хорошее финансирование, крупный город M решил начать капитальный ремонт всего исторического центра. Увидев, что в городе М много начавшихся строек и реконструкций, система в следующем квартале выделяет ему ещё больше денег, но бюджет не безграничен, поэтому часть финансов забирают из суммы, которую в прошлый раз получили мелкие города, где никаких крупных строек не идёт уже лет 50. Как можно догадаться, обрадовавшись ещё большему финансированию, крупный город решает построить себе ещё пару офисных небоскребов и медучреждений с новейшим оборудованием. Вот он, порочный круг. С каждым разом программа будет предназначать все большие суммы крупным городам в ущерб мелким. . Photo by Sharon McCutcheon on Unsplash . &#1047;&#1072;&#1082;&#1083;&#1102;&#1095;&#1077;&#1085;&#1080;&#1077; . Такие ситуации встречаются, и предотвратить их очень сложно, ведь кристально чистых, &quot;непредвзятых&quot; данных практически не бывает. Что же делать? Не доверять все управление полностью системе, должен быть человек, который бы постоянно контролировал предсказания машины. Помните, что это только предсказания, то есть советы, а не точные инструкции. Машина бездушна, она не читала стихи Маяковского и не понимает, что такое хорошо, а что такое плохо. Поэтому прежде, чем следовать совету искуственного интеллекта, включите свой естественный. А моя статья подошла к концу. Спасибо за внимание! Если у вас есть замечания, предложения или другие интересные примеры таких циклов, пишите в комментариях! . Изображение Altmann с сайта Pixabay .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/09/10/Bias-networks.html",
            "relUrl": "/fastpages/jupyter/2020/09/10/Bias-networks.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Первый пост",
            "content": "Мой первый пост будет очень коротким, этакая проба пера (и различных возможностей Markdown-а). Когда начинаешь вести блог, сталкиваешься с кучей проблем: . Во-первых, конечно, встает вопрос, есть ли что-то, что ты можешь рассказать окружающим, что еще не было сказано до тебя? Практически всё сейчас ищется в интернете за пару кликов. Да что там! Даже клики делать не надо, просто говоришь: “Ок, Гугл. Могут ли машины захватить мир?” И результат у тебя перед глазами. | Во-вторых, волей-неволей задумываешься, обладаю ли я достаточным количеством знаний в той или иной области, чтобы еще и делиться своими мыслями на эту тему с другими людьми. | К тому же, число различных блогов растет день ото дня. Есть ли что-то такое, что будет отличать мой блог от сотни других? И все такое прочее. | . Но я сформулировала для себя несколько правил, которые эти проблемы решают, и на которые я и буду опираться в дальнейшем: . Данный блог я веду в первую очередь для себя. Я веду его, чтобы фиксировать свои идеи, чтобы напомнить мне будущей, какую большую работу я проделала, чтобы еще раз рассказать о том, что я узнала и утрамбовать свои знания в голове (кажется, это называется, закрепить полученные навыки). | Едва ли этот блог будет читать кто-то кроме меня. А если на него кто-нибудь чудом и наткнется, буду рада. Но если этому кому-то что-то не понравится - я никого тут не задерживаю. Этот блог не носит никаких коммерческих целей, поэтому нет цели завоевать признание миллионов. | Этот блог я веду в процессе обучения на курсе по машинному обучению. Ведение блога было рекомендацией авторов этого курса, поэтому, вероятно, на английском языке будет огромное число похожих блогов, но, думаю, на русском языке их число сильно меньше. | Что ж, вступление есть, теперь можно приступать к делу. . .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/markdown/2020/09/02/first-post.html",
            "relUrl": "/markdown/2020/09/02/first-post.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Искусственный интеллект и все-все-все",
            "content": "Очень часто люди, не имеющие дела с искуственным интеллектом лично, думают, что &quot;искусственный интеллект&quot;, &quot;машинное обучение&quot; и &quot;глубокое обучение&quot; - взаимо заменяемые словосочетания. Однако, это не совсем так. . Давайте посмотрим, какое определение искусственному интеллекту дает толковый словарь по искусственному интеллекту: . Интеллект Искусственный - научное направление, в рамках которого ставятся и решаются задачи аппаратного или программного моделирования тех видов человеческой деятельности, которые традиционно считаются интеллектуальными. . То есть это самый общий термин из всех трех, он, как можно догадаться, включает в себя все остальные, и обозначает целую область знаний. . Стоит заметить, что в обиходе под искусственным интеллектом обычно понимается умение машины выполнять какие-то действия наравне с человеком (или даже лучше). Здесь лучше подойдет второе определение: . Интеллект Искусственный - свойство интеллектуальных систем выполнять функции (творческие), которые традиционно считаются прерогативой человека. . . С искусственным интеллектом все вроде бы понятно. Этот термин можно почти безошибочно применять ко всему, что нам кажется достаточно умным для машины :) Перейдем к машинному обучению. Что это такое? Вот определение, которое я для себя вывела. . Машинное обучение - огромный подраздел искусственного интеллекта, характерной чертой которого является то, что алгоритм поиска решения некоторой задачи строится не на том, что мы пишем определенную последовательность команд, выполнение которых приводит к ответу, а на том, что машина сама находит закономерности в предоставленных ей данных и на основании этих закономерностей делает предсказания, каким может быть ответ. . Чтобы запомнить, что машинное обучение - только подраздел искуственного интеллекта, упомяну несколько других таких же подразделов: . Интеллектуальная робототехника | Экспертные системы | Машинное творчество и т.д. | . Конечно, зачастую эти подразделы переплетаются между собой. Главное, что отличает машинное обучение от остальных подразделов - самостоятельное получение машиной новых знаний. . Теперь глубокое обучение (deep learning). Глубокое обучение - один из видов машинного обучения. Это такой способ извлечения и обработки данных, который базируется на многослойных нейронных сетях. . Как это работает? Если в двух словах, то каждый слой сети состоит из нескольких нейронов. Каждый нейрон получает на вход данные от нейронов предыдущего уровня, обрабатывает полученную информацию, и передает обработанные данные нейронам из следующего слоя. . Это очень коротко и непонятно, но подробнее напишу об этом позже. Пока достаточно запомнить, что помимо глубокого обучения, есть еще такие виды машинного обучения, как: . Классические методы обучения (с учителем/без учителя) | Ансамблевые методы (Стеккинг, Беггинг, Бустинг) | Обучение с подкреплением | . Различных методов очень много и классифицировать их можно по-разному. Основное, что отличает глубокое обучение от остальных методов, это то, что обучение происходит на нейронных сетях с несколькими слоями. . Искусственный интеллект уже стал частью нашей повседневной жизни. Далее привожу примеры успешного использования ИИ. . Компьютерное зрение: . Распознавание номеров автомобилей | Распознавание лиц | Беспилотные автомобили | Поиск фотографий на телефоне по таким запросам, как &quot;закат&quot;, &quot;пикник&quot;, &quot;Новый год&quot; и т.д. | . В медицине: . Диагностирование рака | Нахождение различных патологий на рентгеновских снимках, МРТ и др. | . Обработка естественного языка: . Распознавание речи (&quot;Привет, Алиса&quot;, &quot;Ок, Google&quot; и т.п.) | Классификация документов по темам | Поддержание разоговора, ответы на вопросы (различные чат-боты) | Генерация текста | . А так же: . Рекомендательные системы: Расположение ссылок в поисковиках по релевантности, подбор фильмов, &quot;Вам также может понравиться...&quot;, контекстная реклама и вот это всё. . Игры: Искуственный интеллект уже обыграл человека в шахматы и Го, а помимо этого умеет проходить много других игр. . На видео: программист из Австралии научил ИИ играть в динозаврика из Chrome. Видео длинное, но посмотреть любопытно. . И многое-многое другое... ИИ врывается во многие сферы жизни, и мы сами уже не замечаем, что встречаемся с ним ежедневно. . &#1050;&#1072;&#1082; &#1088;&#1072;&#1073;&#1086;&#1090;&#1072;&#1077;&#1090; &#1085;&#1077;&#1081;&#1088;&#1086;&#1085;&#1085;&#1072;&#1103; &#1089;&#1077;&#1090;&#1100;? . Представим ситуацию: нам нужно отправить большой архив фотографий бабушке, но при этом не хотим, чтобы она увидела, что кто-то из её любимых внуков завел дома удава. Руками перебирать все фотографии очень долго, поэтому мы хотим написать такую программу, которая сама могла бы определить, есть ли на фото удав или нет. Время выхода нейронной сети на сцену! . Мы хотим, чтобы общая концепция была такая: скармливаем фото программе, она что-то с ней делает, а нам только выдает результат: &quot;Все отлично, удава здесь нет&quot;. . На самом деле, программе не достаточно получить только фотографию, она еще хочет получить параметры - набор значений для её внутренних переменных, чтобы она точно знала, что делать с входными данными - искать удава или искать закат. То, что мы получим на выходе, напрямую зависит от этих самых параметров. . Откуда нам взять параметры? . С разными параметрами наша модель (модель - программа, поведение которой определяется параметрами) и предсказывает по-разному. Чтобы достичь максимума точности в таком непростом деле, как детектирование удава, было бы неплохо, если бы она сама умела сравнивать эффективность при разных параметрах и запоминать лучшие. А еще мы бы хотели, чтобы она сама умела подбирать параметры так, чтобы её точность повышалась. . Например, подаем мы ей на вход параметры (а1, а2, а3, ... ,аn) и набор фотографий с пометками о наличии на них удава. Модель берет фотографию и говорит: &quot;Здесь есть удав с вероятностью 60%&quot;. Потом смотрит в ответы и видит, что удав тут и на самом деле есть. Тогда она думает: &quot;Хм, параметр а10 сбил меня с мысли, а ведь параметры а11 и а25 мне говорили, что тут точно есть удав&quot;. Берет следующую фотографию. Точно так же делает предположение, сверяет с ответом, смотрит, какие параметры надо поменять. Когда она проделает это со всеми поданными на вход фотографиями, она определяет точность, с которой она сейчас умеет определять удава. Например, она находит удава на фото в 75% случаев. Теперь она предлагает поменять определенные параметры, например, а10 уменьшить, а а11 и а25 увеличить.Теперь с этими параметрами она снова берет все фотографии и проделывает все то же самое. И оп! С такими параметрами она находит удава в 83% случаев. Опять корректирует значения и так далее. Прелесть в том, что модель делает все это без нашей помощи и учится на своих ошибках. . При этом модели важно не просто то, что она сказала, что &quot;здесь есть удав&quot;, но и еще и то, с каким качеством она это сделала, насколько она уверена в своих результатах. И её цель - повысить именно это качество, стать увереннее в себе :), а не просто выдать какой-то ответ. . Когда нам нравится качество, с которым модель предсказывает результаты, мы сохраняем параметры, при которых оно достигается. Теперь наша модель уже обучена. В следующий раз нам не придется заново учить её опознавать удавов - мы загружаем ей свои фотографии (уже без ответов), а она, пользуясь параметрами, полученными в прошлый раз, сразу выдает результат. . . Внесем ясность: . Получается, обучение модели (fit, train) - подбор параметров таким образом, чтобы на помеченных данных точность предсказаний была максимальной. . Заметим, что модель состоит из некоторой функции (архитектуры) и параметров. . В качестве архитектуры модели тут как раз будут использоваться нейронные сети. . В качестве метода улучшения параметров - функции оптимизации - часто выступает SGD (стохастический градиентный спуск). . Результаты, которые выдает модель, называются предсказаниями (predictions). . Полное прохождение всех входных данных одного цикла называется эпохой (epoch). . Функция, с помощью которой измеряется качество, называется функцией потерь (loss). Функция потерь выбирается так, чтобы её понимала сама модель и на её основании делала вывод, какие параметры как поменять. Если же мы уже обучили нейросеть и хотим похвастаться другу, как она хороша, или если мы хотим более точно понимать, насколько хороша модель в конце каждой эпохи и какое качество она показывает на валидационной выборке (что это такое будет ниже), мы используем метрики. Метрика - понятная для человека функция, показывающая эффективность модели. . А правильные ответы, которые мы загружаем вместе с фотографиями при обучении модели и которые пытается отгадать модель, по-английски называются labels или targets, а в русском языке я их названий точно не знаю, может, таргеты или лейблы :) . . Итак, повторим еще раз: . В архитектуру загружаются входные данные (например, фотографии) и параметры. Архитектура делает предсказания. Затем они сверяются с таргетами и функция потерь выдает качество модели. С помощью функции оптимизации улучшаем параметры и снова загружаем их в архитектуру вместе в входными данными. Следующая эпоха. . Примечание: Думаю, очевидно, что после обучения модель сможет распознавать только такие шаблоны, которые встречала во входных данных. Если она училась только на фотографиях кошек, то она не сможет распознать кошку, нарисованную от руки. . Представим ситуацию: мы выдали модели большое число помеченных фотографий с удавами и без, обучение проходит идеально: точность 100%. Сохраняем эти параметры и на радостях загружаем фотографию, где мы обнимаемся с удавом. И вдруг результат: на этой фотографии удава нет. Как же так? Ведь модель обещала нам стопроцентную точность! Скорее всего, дело в том, что модель во время обучения просто запомнила все наши картинки и их таргеты, поэтому и выдавала к ним все время верные ответы, а саму суть (то, как выглядит удав) так и не поняла. Говорят, что модель ПЕРЕобучилась (overfitting). Чтобы этого избежать, обычно перед обучением входные помеченные данные делят на две группы - обучающая выборка (trainig set) и проверочная выборка (validation set). Обычно для проверки используют 20-30% всех данных. Процесс обучения проходит только на обучающей выборке, а эффективность модели в конце каждой эпохи оценивается на проверочной, потому что эти данные модель раньше точно не видела и точно не могла их выучить. Причем каждый раз эта валидационная выборка, однажды выбранная, должна оставаться одной и той же. В большинстве случаев данные, входящие в эту выборку выбираются из общего числа данных случайным образом, но в некоторых случаях оценка точности на случайной выборке не является адекватным критерием эффективности. Например, мы хотим каким-то образом научить модель предсказывать ближайший рост или падение акций компании N на основе имеющейся у нас истории поведения стоимости её акций за прошлые 10 лет. Если мы в валидационную выборку включим случайные даты из последних 10 лет, то модель может догадаться, сколько стоили акции на основе предыдущего и последующего дней. Однако в реальности у нас нет этого &quot;последующего&quot; дня: мы хотим угадать стоимость акций завтра, но не знаем, сколько они будут стоить послезавтра. Поэтому для проверки реальной эффективности, логичнее в валидиционную выборку включить, например, последние 2 месяца из имеющейся у нас истории и посмотреть, насколько предсказания модели соответствуют действительности. То есть если наши предсказания будут каким-то образом упорядочены по оси времени, то к формированию проверочной выборки надо относиться аккуратнее! . Примечание: Несмотря на то, что мы заблаговременно разделили наши данные на обучающие и проверочные, мы все равно можем столкнуться с проблемой запоминания данных. Но так мы хотя бы сможем установить этот факт уже в процессе обучения, а не после: точность на обучающей выборке будет расти, в то время как точность на валидационной выборке будет ухудшаться. . Обычно присутствует еще тестовая выборка (test set), для самой финальной проверки. Её модель не видит ни разу за время обучения, и ею проверяют точность на самой последней стадии работы. Например, на соревнованиях эту выборку не видят участники, она доступна только для проверки сданных работ(моделей). Или если вам делают модель на заказ, то часть размеченных данных заказчик может оставить себе, не показывая разработчику, и уже при приемке готовой работы проверить точность модели на этих данных. . Конечно, модель можно полностью написать самому. Но если вы не тот самый человек, который готов потратить огромное количество времени на написание собственной модели, не будучи уверенным, что она даст сильный выигрыш по времени, то будет гораздо удобнее взять уже готовые модели и дообучать их на своем конкретном случае. Такие модели называются предобученными, так как они уже обучились на каких-то больших наборах данных (dataset). Таких готовых моделей существует очень много. Например, для классификации изображений существуют такие готовые модели, как ResNet или VGG. Они обучены уже на огромном датасете ImageNet и уже умеют находить на изображении множество разных шаблонов. . ImageNet - один из самых известных бесплатных больших дасатетов. Он насчитывает наборы изображений для более, чем 100000 классов. Для каждого класса предоставляется в среднем 1000 картинок. Пометки о том, к какому классу относится изображение, сделаны людьми, и качество данных контролируется. . Для задач компьютерного зрения используются сверточные нейронные сети, сокращенно - CNN (Convolutional neural network). Как несложно догадаться, они используют операцию свертки. О том, как именно они работают будет в одной из следующих статей. . При работе с изображениями перед обучением данные обычно обрабатывают различными способами, чтобы получить еще больше данных. Например, увеличивают яркость, вращают, растягивают, добавляют шум и т.д. Английский термин для этого - data augmentation. Но в любом случае перед загрузкой в модель все файлы приводят к одинаковому размеру. Обычно можно увидеть приведение к размеру 224x224, но число 224 не несет в себе особой смысловой нагрузки. Так сложилось исторически и не более чем формальность - вы можете выбрать другой размер. Чем больше размер - тем лучших результатов можно достичь, правда, ценой будет более долгий процесс обучения и бОльшие требуемые мощности. . На сегодня, пожалуй, хватит. В этой статье я ввела множество основных терминов, но не углублялась в теорию. Если у вас есть вопросы или замечания, пишите в комментариях, а я пошла готовить следующую статью. До новых встреч! . Photo by Jan Tinneberg on Unsplash .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/fastpages/jupyter/2020/09/02/IA-and-everything.html",
            "relUrl": "/fastpages/jupyter/2020/09/02/IA-and-everything.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://irinaprokofieva.github.io/my-ml-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://irinaprokofieva.github.io/my-ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://irinaprokofieva.github.io/my-ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}